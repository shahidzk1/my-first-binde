{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from scipy.stats import uniform\n",
    "\n",
    "import weakref \n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "from data_cleaning import clean_df\n",
    "from KFPF_lambda_cuts import KFPF_lambda_cuts\n",
    "from plot_tools import AMS, preds_prob, plot_confusion_matrix, plt_sig_back\n",
    "import tree_importer \n",
    "import uproot\n",
    "\n",
    "\n",
    "#To save some memory we will delete unused variables\n",
    "class TestClass(object): \n",
    "    def check(self): \n",
    "        print (\"object is alive!\") \n",
    "    def __del__(self): \n",
    "        print (\"object deleted\") \n",
    "        \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "executor = ThreadPoolExecutor(7)\n",
    "\n",
    "import gc\n",
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_signal = uproot.open('/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/dcm/dcm_signal.root:plain_tree',decompression_executor=executor,\n",
    "                                  interpretation_executor=executor).arrays(library='pd',decompression_executor=executor,\n",
    "                                  interpretation_executor=executor)\n",
    "aa = ['b', 'chi2geo','chi2primneg', 'chi2primpos', 'chi2_topo', 'cosine_first', 'cosine_second', 'cosine_topo', 'distance', 'eta', 'l', 'ldl', 'mass', 'p', 'pT', 'phi', 'px', 'py', 'pz', 'rapidity', 'vtx_chi2_first', 'vtx_chi2_second',\n",
    " 'z_first', 'z_second', 'z_smaller', 'M', 'issignal', 'id', 'nhits_mvd_first', 'nhits_mvd_second', 'nhits_mvd_sum', 'nhits_tot_first', 'nhits_tot_second', 'nhits_tot_sum', 'pid']\n",
    "df_clean_signal.columns=aa\n",
    "signal = df_clean_signal[ (df_clean_signal['mass']>df_clean_signal['mass'].mean()-1.5*df_clean_signal['mass'].std())\n",
    "               & (df_clean_signal['mass']<df_clean_signal['mass'].mean()+1.5*df_clean_signal['mass'].std()) & (df_clean_signal['M']>200) & (df_clean_signal['M']<250)]\n",
    "del df_clean_signal\n",
    "signal[\"issignal\"].replace({3: 2, 4: 2, 5:2}, inplace=True)\n",
    "\n",
    "\n",
    "a = ['index', 'chi2geo','chi2primneg', 'chi2primpos','distance', 'ldl','l','cosine_first', 'cosine_second', 'chi2_topo', 'cosine_topo',\n",
    " 'mass', 'pT', 'b', 'eta', 'p', 'phi', 'rapidity', 'vtx_chi2_first', 'vtx_chi2_second', 'z_first', 'z_second', 'z_smaller', 'M', 'issignal', 'nhits_mvd_first',\n",
    " 'nhits_mvd_second', 'nhits_mvd_sum', 'nhits_tot_first', 'nhits_tot_second', 'nhits_tot_sum']\n",
    "\n",
    "df_clean_urqmd = uproot.open('/home/shahid/Mount/gsi/u/Mount/lustre/khan/cbmsoft/at_tree_plainer/install/bin/urqmd/c_0_pt_0_9_y_0_9_M_200_250_urqmd.root:plain_tree',decompression_executor=executor,\n",
    "                                  interpretation_executor=executor).arrays(library='pd',decompression_executor=executor,\n",
    "                                  interpretation_executor=executor)\n",
    "df_clean_urqmd.columns = a\n",
    "df_clean_urqmd[\"issignal\"].replace({3: 2, 4: 2, 5:2}, inplace=True)\n",
    "\n",
    "df_clean =  uproot.open('/home/shahid/Mount/gsi/u/Mount/lustre/khan/cbmsoft/at_tree_plainer/install/bin/dcm/c_0_pt_0_9_y_0_9_M_200_250_dcm.root:plain_tree',decompression_executor=executor,\n",
    "                                  interpretation_executor=executor).arrays(library='pd',decompression_executor=executor,\n",
    "                                  interpretation_executor=executor)\n",
    "df_clean.columns = a\n",
    "df_clean[\"issignal\"].replace({3: 2, 4: 2, 5:2}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "back = df_clean_urqmd[(df_clean_urqmd['issignal'] == 0)\n",
    "                & ((df_clean_urqmd['mass'] > 1.077)\n",
    "                & (df_clean_urqmd['mass'] < 1.1) | (df_clean_urqmd['mass']>1.135) \n",
    "                   & (df_clean_urqmd['mass'] < 1.2))]\n",
    "\n",
    "signal_selected= signal[(signal['mass']>1.1) & (signal['mass']<1.135)]\n",
    "background_selected = back.sample(n=3*(signal_selected.shape[0]))\n",
    "del back\n",
    "gc.collect()\n",
    "dfs = [signal_selected, background_selected]\n",
    "df_scaled = pd.concat(dfs)\n",
    "df_scaled = df_scaled.sample(frac=1)\n",
    "del signal, signal_selected, background_selected, dfs\n",
    "\n",
    "print(df_scaled.shape)\n",
    "print(df_scaled[df_scaled['issignal']==1].shape)\n",
    "print(df_scaled[df_scaled['issignal']==2].shape)\n",
    "\n",
    "fig, axs = plt_sig_back(df_scaled)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(8)\n",
    "axs.text(1.13, 6000, r'DCM-QGSM-SMM', color = 'magenta',  fontsize=15)\n",
    "axs.text(1.13, 4000, r'Au+Au @ 12 $A$GeV/$c$', color = 'magenta',  fontsize=15)\n",
    "axs.text(1.13, 2000, r'URQMD, Au+Au @ 12 $A$GeV/$c$', fontsize=15)\n",
    "fig.savefig(\"hists.pdf\")\n",
    "\n",
    "cuts = [ 'chi2geo', 'chi2primneg', 'chi2primpos', 'chi2_topo', 'cosine_topo', 'distance', 'ldl', 'nhits_mvd_first','nhits_mvd_second','nhits_tot_first','nhits_tot_second']\n",
    "x = df_scaled[cuts].copy()\n",
    "y =pd.DataFrame(df_scaled['issignal'], dtype='int8')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=324, stratify=y)\n",
    "dtrain = xgb.DMatrix(x_train, label = y_train)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "starttime = time.time()\n",
    "\n",
    "\n",
    "#Bayesian Optimization function for xgboost\n",
    "#specify the parameters you want to tune as keyword arguments\n",
    "def bo_tune_xgb(max_depth, gamma, alpha, n_estimators ,learning_rate):\n",
    "    params = {'max_depth': int(max_depth),\n",
    "              'gamma': gamma,\n",
    "              'alpha':alpha,\n",
    "              'n_estimators': n_estimators,\n",
    "              'learning_rate':learning_rate,\n",
    "              'subsample': 0.8, \n",
    "              'num_class':np.unique(dtrain.get_label()).shape[0], \n",
    "              'eval_metric': 'auc','tree_method':'hist', 'nthread' : 7}\n",
    "    cv_result = xgb.cv(params=params, dtrain=dtrain, num_boost_round=10, nfold=5)\n",
    "    return  cv_result['test-auc-mean'].iloc[-1]\n",
    "\n",
    "#Invoking the Bayesian Optimizer with the specified parameters to tune\n",
    "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth': (4, 10),\n",
    "                                             'gamma': (0, 1),\n",
    "                                            'alpha': (2,20),\n",
    "                                             'learning_rate':(0.01,1),\n",
    "                                             'n_estimators':(100,1000)\n",
    "                                            })\n",
    "cpproot_time = time.time() - starttime\n",
    "print(f\"total time: {cpproot_time} sec\")\n",
    "#performing Bayesian optimization for 5 iterations with 8 steps of random exploration with an #acquisition function of expected improvement\n",
    "xgb_bo.maximize(n_iter=5, init_points=5, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_param = xgb_bo.max['params']\n",
    "param= {'alpha': max_param['alpha'], 'gamma': max_param['gamma'], 'learning_rate': max_param['learning_rate'],\n",
    "        'max_depth': int(round(max_param['max_depth'],0)), 'n_estimators': int(round(max_param['n_estimators'],0)), \n",
    "         'objective':'binary:logistic','tree_method':'hist','nthread' : 7}\n",
    "\n",
    "#Fit/train on training data\n",
    "bst = xgb.XGBClassifier(**param).fit(x_train, y_train)\n",
    "del x_train, y_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_whole = df_clean[cuts].copy()\n",
    "bst_test1 = pd.DataFrame(data=bst.predict_proba(x_whole))\n",
    "df_clean['xgb_preds0'], df_clean['xgb_preds1'], df_clean['xgb_preds2']= bst_test1[0], bst_test1[1], bst_test1[2]\n",
    "del x_whole, bst_test1\n",
    "\n",
    "x_whole_1 = df_clean_urqmd[cuts].copy()\n",
    "bst_test2 = pd.DataFrame(data=bst.predict_proba(x_whole_1))\n",
    "df_clean_urqmd['xgb_preds0'], df_clean_urqmd['xgb_preds1'], df_clean_urqmd['xgb_preds2']= bst_test2[0], bst_test2[1], bst_test2[2]\n",
    "del x_whole_1,  bst_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = xgb.plot_importance(bst)\n",
    "plt.rcParams['figure.figsize'] = [5, 3]\n",
    "plt.show()\n",
    "ax.figure.tight_layout() \n",
    "ax.figure.savefig(\"hits.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_prob(df,preds,true,df1,preds1, true1):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    bins1=100\n",
    "    TP = df[(df[true]==1)]\n",
    "    TN = df[(df[true]==0)]\n",
    "    \n",
    "    plt.hist(TN[preds], bins=bins1,facecolor='blue',alpha = 0.3, label='background in train')\n",
    "    plt.hist(TP[preds], bins=bins1,facecolor='red',alpha = 0.3, label='signal in train')\n",
    "    del TP, TN\n",
    "    \n",
    "    TP1 = df1[(df1[true1]==1)]\n",
    "    TN1 = df1[(df1[true1]==0)]\n",
    "    \n",
    "    hist1, bins1 = np.histogram(TN1[preds1], bins=bins1)\n",
    "    err1 = np.sqrt(hist1)\n",
    "    center1 = (bins1[:-1] + bins1[1:]) / 2\n",
    "    plt.errorbar(center1, hist1, yerr=err1, fmt='o',\n",
    "                 c='blue', label='background in test')\n",
    "    \n",
    "    hist, bins = np.histogram(TP1[preds1], bins=bins1)\n",
    "    err = np.sqrt(hist)\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.errorbar(center, hist, yerr=err, fmt='o',\n",
    "                 c='red', label='signal in test')\n",
    "    del TP1, TN1\n",
    "    \n",
    "   # ax.annotate('cut on probability', xy=(0, 90),  xycoords='data',xytext=(0.13,0.5), textcoords='axes fraction',\n",
    "    #            fontsize=15,arrowprops=dict(facecolor='black', shrink=0.05),horizontalalignment='right', verticalalignment='top')\n",
    "    \n",
    "    \n",
    "    \n",
    "    if df[true].unique().shape[0]>2:\n",
    "        TP2= df[df[true]>1]\n",
    "        plt.hist(TP2[preds], bins=bins1,facecolor='green',alpha = 0.3, label='secondaries in train')\n",
    "        TP2= df1[df1[true1]>1]\n",
    "        hist2, bins2 = np.histogram(TP2[preds1], bins=bins1)\n",
    "        center2 = (bins2[:-1] + bins2[1:]) / 2\n",
    "        err2 = np.sqrt(hist2)\n",
    "        plt.errorbar(center2, hist2,yerr=err2, fmt='o',c='green',label='secondaries in test')\n",
    "\n",
    "    del TP2\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Probability',fontsize=18)\n",
    "    plt.ylabel('Counts', fontsize=18)\n",
    "    ax.set_xticks(np.arange(0,1.1,0.1))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=16)\n",
    "    plt.legend(fontsize=18)\n",
    "    fig.show()\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 0.08\n",
    "df = df_clean[df_clean['xgb_preds0']<cut]\n",
    "#df = df[df['xgb_preds1']>0.6]\n",
    "#df = df[df['xgb_preds2']>0.1]\n",
    "for i in ['xgb_preds0','xgb_preds1','xgb_preds2']:\n",
    "#for i in ['xgb_preds2']:\n",
    "    fig, ax = preds_prob(df,i, 'issignal',df,i, 'issignal')\n",
    "    plt.legend([\"back\",\"prim\",\"second\"],fontsize=18)\n",
    "    plt.title(str(i))\n",
    "    fig.savefig(\"hists\"+str(i)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut3 = 0.08\n",
    "df3_base=df[(df['xgb_preds0']<cut3) ]\n",
    "eff1 = (df3_base[(df3_base['issignal']==1)].shape[0])/ (df_clean_urqmd[(df_clean_urqmd['issignal']==1)].shape[0])\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(12, 8))\n",
    "range1= (1.105, 1.14)\n",
    "bins1 = 150\n",
    "\n",
    "df3_base['mass'].plot.hist(bins = bins1, range=range1, facecolor='red',alpha = 0.3,grid=True,sharey=True, label='XGB selected $\\Lambda$s')\n",
    "#df3_base[df3_base['issignal']==1]['mass'].plot.hist(bins = 300, range=range1,facecolor='blue',alpha = 0.3,grid=True,sharey=True, '\\n True positives = \\n (MC =1)\\n signal in \\n the distribution')\n",
    "#df3_base[df3_base['issignal']==1]['mass'].plot.hist(bins = bins1, range=range1,facecolor='magenta',alpha = 0.3,grid=True,sharey=True )\n",
    "df3_base[df3_base['issignal']==0]['mass'].plot.hist(bins = bins1, range=range1,facecolor='green',alpha = 0.3,grid=True,sharey=True, label ='\\n False positives = \\n (MC =0)\\n background in \\n the distribution')\n",
    "\n",
    "plt.legend( fontsize = 18, loc='upper right')\n",
    "#plt.rcParams[\"legend.loc\"] = 'upper right'\n",
    "plt.title(\"XGB selected $\\Lambda$ candidates with a cut of %.3f \"%cut3 +\"on the XGB back probability distribution\", fontsize = 18)\n",
    "axs.set_xlabel(\"Mass (GeV/${c^2}$)\", fontsize = 18)\n",
    "plt.ylabel(\"Counts\", fontsize = 18)\n",
    "axs.text(1.123, 4000, 'CBM Performance', fontsize=18)\n",
    "axs.text(1.123, 3500, 'URQMD, Au+Au @ 12A GeV/$c$', fontsize=18)\n",
    "axs.text(1.123, 3000, \"Primaries efficiency = %.3f\"%eff+\"\", fontsize=18)\n",
    "axs.tick_params(labelsize=18)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"whole_sample_invmass_with_ML.png\")\n",
    "del df3_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "cut = 0.8\n",
    "df3 = df_clean[df_clean['xgb_preds0']<cut]\n",
    "df3 = df3[df3['issignal']>0]\n",
    "df3 = df3[['pT', 'rapidity', 'mass','issignal','xgb_preds1']]\n",
    "df3.columns.values[[0,1,2,3,4]] = ['MCpT', 'MCrapidity','MCmass', 'MCissignal','MCxgb_preds']\n",
    "df3[\"MCissignal\"]=df3[\"MCissignal\"].astype(\"float\")\n",
    "df3[\"MCxgb_preds\"]=df3[\"MCxgb_preds\"].astype(\"float\")\n",
    "del df_clean\n",
    "\n",
    "df3_base = df_clean_urqmd[df_clean_urqmd['xgb_preds0']<cut]\n",
    "df3_base3 = df3_base[['pT', 'rapidity', 'mass', 'issignal','xgb_preds1']]\n",
    "df3_base3[\"issignal\"]=df3_base3[\"issignal\"].astype(\"double\")\n",
    "df3_base3[\"xgb_preds\"]=df3_base3[\"xgb_preds\"].astype(\"double\")\n",
    "del df_clean_urqmd, df3_base\n",
    "file = uproot.recreate(\"new_c3_pt_y_y_yield_bdt_cut_0.8.root\")\n",
    "file[\"t1\"] = df3_base3\n",
    "file[\"t2\"] = df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "cut = 0.8\n",
    "df3 = df_clean[df_clean['xgb_preds0']<cut]\n",
    "df3_base = df_clean_urqmd[df_clean_urqmd['xgb_preds0']<cut]\n",
    "file = uproot.recreate(\"new_c3_pt_y_y_yield_bdt_cut_0.8.root\")\n",
    "file[\"t1\"] = df3_base\n",
    "file[\"t2\"] = df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-shopper",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
