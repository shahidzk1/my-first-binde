{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "from tree_importer import tree_importer\n",
    "\n",
    "inFile = ROOT . TFile . Open ( \"urqmd_efficiency_pt_y_yield_bdt_cut_0.9.root\" ,\" READ \")\n",
    "inFile1 = ROOT . TFile . Open ( \"dcm_100_efficiency_pt_y_yield_bdt_cut_0.9.root\" ,\" READ \")\n",
    "inFile.ls()\n",
    "\n",
    "hist_2d = inFile1.Get(\"recons\")\n",
    "hist_2d_1 = inFile1.Get(\"Efficiency\")\n",
    "hist_2d_2 = inFile.Get(\"Mc_urqmd\")\n",
    "hist_2d_3 = inFile1.Get(\"recons\")\n",
    "\n",
    "\n",
    "canvas = ROOT . TCanvas (\" canvas \",\"\", 950,800)\n",
    "canvas.Draw()\n",
    "canvas.SetGrid()\n",
    "\n",
    "sum_mc=sum(hist_2d)\n",
    "\n",
    "hist_2d.SetStats(0)\n",
    "hist_2d.GetZaxis().SetRangeUser (0 ,0.4)\n",
    "hist_2d.GetYaxis().SetRangeUser (0 ,3)\n",
    "\n",
    "aaa = hist_2d.Divide(hist_2d_2)\n",
    "\n",
    "hist_2d.Draw(\"colz\")\n",
    "hist_2d . SetTitle (\"\")\n",
    "hist_2d .GetXaxis().SetTitle(\"#it{y_{Lab}}\")\n",
    "hist_2d. GetXaxis().SetTitleSize(0.06)\n",
    "hist_2d .GetXaxis().SetTitleOffset(0.7)\n",
    "hist_2d .GetXaxis().SetLabelSize(0.05)\n",
    "hist_2d .GetYaxis().SetTitle(\"p_{T} (GeV/#it{c})\")\n",
    "hist_2d. GetYaxis().SetTitleSize(0.06)\n",
    "hist_2d .GetYaxis().SetTitleOffset(0.7)\n",
    "hist_2d .GetYaxis().SetLabelSize(0.05)\n",
    "hist_2d .GetZaxis().SetLabelSize(0.03)\n",
    "latex = ROOT . TLatex ()\n",
    "latex . SetNDC ()\n",
    "latex . SetTextSize (0.04)\n",
    "latex . DrawLatex (0.12 ,0.65, \"Total Efficiency = #Lambda_{Reconstructed} / #Lambda_{Simulated} \" )\n",
    "\n",
    "latex.Draw()\n",
    "\n",
    "latex1 = ROOT . TLatex ()\n",
    "latex1 . SetNDC ()\n",
    "latex1 . SetTextSize (0.035)\n",
    "latex1. DrawLatex (0.12 ,0.8, \"CBM performance\")\n",
    "latex1. DrawLatex (0.12 ,0.75, \"DCM-QGSM-SMM, Au+Au @ 12#it{A} GeV/#it{c}\")\n",
    "latex1 . DrawLatex (0.35 ,0.6, \"= %.f / %.f = %.3f\"%(sum_mc,sum(hist_2d_2), sum_mc / (sum(hist_2d_2))))\n",
    "latex1.Draw()\n",
    "canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/apr20_fr_18.2.1_fs_jun19p1/dcmqgsm_smm_pluto/auau/12agev/mbias/sis100_electron_target_25_mkm/PFSimplePlainTree_11_20.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/shahid/Mount/gsi/u/filelist.txt', 'a') as the_file:\n",
    "    for i in range(1,11,1):\n",
    "        the_file.write('/lustre/cbm/users/lubynets/cbm2atree/outputs/apr20_fr_18.2.1_fs_jun19p1/dcmqgsm_smm_pluto/auau/12agev/mbias/sis100_electron_target_25_mkm/AT2/'+str(i)+'/'+str(i)+'.analysistree.root\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filelist for urqmd\n",
    "l = 1\n",
    "for j in range(1001,3001):\n",
    "    if j%5==0:\n",
    "        l=l+1\n",
    "    with open('/home/shahid/Mount/gsi/u/Mount/lustre/khan/filelists/urqmd/filelist_urqmd_'+str(l)+'.txt', 'a') as the_file:\n",
    "        the_file.write('/lustre/cbm/users/lubynets/cbm2atree/outputs/apr20_fr_18.2.1_fs_jun19p1/urqmd_pluto/auau/12agev/mbias/sis100_electron_target_25_mkm/AT2/'+str(j)+'/'+str(j)+'.analysistree.root\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 1\n",
    "for j in range(1,5001):\n",
    "    if j%5==0:\n",
    "        l=l+1\n",
    "    with open('/home/shahid/Mount/gsi/u/Mount/lustre/khan/filelists/dcm/filelist_dcm_'+str(l)+'.txt', 'a') as the_file:\n",
    "        the_file.write('/lustre/cbm/users/lubynets/cbm2atree/outputs/apr20_fr_18.2.1_fs_jun19p1/dcmqgsm_smm_pluto/auau/12agev/mbias/sis100_electron_target_25_mkm/AT2/'+str(j)+'/'+str(j)+'.analysistree.root\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to convert pfsimple output to plaintree with impact parameter\n",
    "with open('/home/shahid/Mount/gsi/u/filelist_urqmd_plain_tree.txt', 'a') as the_file:\n",
    "    for i in range(1001,1625,1):\n",
    "        the_file.write('/lustre/cbm/users/lubynets/cbm2atree/outputs/apr20_fr_18.2.1_fs_jun19p1/dcmqgsm_smm_pluto/auau/12agev/mbias/sis100_electron_target_25_mkm/AT2/'+str(i)+'/'+str(i)+'.analysistree.root\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to convert pfsimple output to plaintree with impact parameter\n",
    "with open('/home/shahid/Mount/gsi/u/filelist_dcm_plain_tree.txt', 'a') as the_file:\n",
    "    for i in range(1,1000,1):\n",
    "        the_file.write('/lustre/cbm/users/khan/pfsimple/outputs/apr20_fr_18.2.1_fs_jun19p1/dcm/auau/12agev/mbias/sis100_electron_target_25_mkm/'+str(i)+'/PFSimpleOutput.'+str(i)+'.root\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to convert pfsimple output to plaintree with impact parameter\n",
    "with open('/home/shahid/Mount/gsi/u/filelist_dcm_plain_tree.txt', 'a') as the_file:\n",
    "    for i in range(1,126,1):\n",
    "        the_file.write('/lustre/cbm/users/khan/pfsimple/outputs/apr20_fr_18.2.1_fs_jun19p1/dcm/auau/12agev/mbias/sis100_electron_target_25_mkm/'+str(i)+'/PFSimpleOutput.'+str(i)+'.root\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/shahid/Mount/gsi/u/flat_trees/filelist.txt', 'a') as the_file:\n",
    "    for i in range(1001,1101,1):\n",
    "        the_file.write('/lustre/cbm/users/lubynets/cbm2atree/outputs/apr20_fr_18.2.1_fs_jun19p1/urqmd_pluto/auau/12agev/mbias/sis100_electron_target_25_mkm/AT1/'+str(i)+'/'+str(i)+'.analysistree.root\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/shahid/Mount/gsi/u/filelist3.txt', 'a') as the_file:\n",
    "    for i in range(400,625,1):\n",
    "        the_file.write('/lustre/cbm/users/lubynets/cbm2atree/outputs/apr20_fr_18.2.1_fs_jun19p1/dcmqgsm_smm_pluto/auau/12agev/mbias/sis100_electron_target_25_mkm/AT2/'+str(i)+'/'+str(i)+'.analysistree.root\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/shahid/Mount/gsi/u/filelist_urqmd_1.txt', 'a') as the_file:\n",
    "    for i in range(1001,1200,1):\n",
    "        the_file.write('/lustre/cbm/users/lubynets/cbm2atree/outputs/apr20_fr_18.2.1_fs_jun19p1/urqmd_pluto/auau/12agev/mbias/sis100_electron_target_25_mkm/AT2/'+str(i)+'/'+str(i)+'.analysistree.root\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/shahid/Mount/gsi/u/filelist_dcm_plain_tree.txt', 'a') as the_file:\n",
    "    for i in range(1,126,1):\n",
    "        the_file.write('/lustre/cbm/users/khan/pfsimple/outputs/apr20_fr_18.2.1_fs_jun19p1/dcm/auau/12agev/mbias/sis100_electron_target_25_mkm/'+str(i)+'/PFSimpleOutput.'+str(i)+'.root\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    print('/lustre/cbm/users/lubynets/cbm2atree/outputs/apr20_fr_18.2.1_fs_jun19p1/dcmqgsm_smm_pluto/auau/12agev/mbias/sis100_electron_target_25_mkm/AT2/'+str(i)+'/'+str(i)+'.analysistree.root\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main filelist_1.txtinFile1 = ROOT . TFile . Open ( \"dcm_100_efficiency_pt_y_yield_bdt_cut_0.9.root\" ,\" READ \")\n",
    "inFile1.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inFile2 = ROOT . TFile . Open ( \"new_dcm_100_efficiency_pt_y_yield_bdt_cut_0.9.root\" ,\" READ \")\n",
    "inFile2.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inFile = ROOT . TFile . Open ( \"new_urqmd_efficiency_pt_y_yield_bdt_cut_0.9.root\" ,\" READ \")\n",
    "inFile.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "from tree_importer import tree_importer\n",
    "def draw_2d_hist(hist_2d):\n",
    "    c = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "    c.Clear ()\n",
    "    c.SetGrid()\n",
    "    c . Draw() \n",
    "    #ROOT.gStyle.SetImageScaling(1.)\n",
    "    \n",
    "    hist_2d . SetTitle (\"\")\n",
    "    hist_2d .GetXaxis().SetTitle(\"#it{y_{Lab}}\")\n",
    "    hist_2d. GetXaxis().SetTitleSize(0.06)\n",
    "    hist_2d .GetXaxis().SetTitleOffset(0.7)\n",
    "    hist_2d .GetXaxis().SetLabelSize(0.05)\n",
    "    hist_2d .GetYaxis().SetTitle(\"p_{T} (GeV/#it{c})\")\n",
    "    hist_2d. GetYaxis().SetTitleSize(0.06)\n",
    "    hist_2d .GetYaxis().SetTitleOffset(0.7)\n",
    "    hist_2d .GetYaxis().SetLabelSize(0.05)\n",
    "    hist_2d .GetZaxis().SetLabelSize(0.03)\n",
    "    hist_2d.SetStats(0)\n",
    "    \n",
    "    hist_2d.GetYaxis().SetRangeUser (0 ,3)\n",
    "    hist_2d.GetZaxis().SetRangeUser (0 ,0.4)\n",
    "    #hist_2d.GetZaxis().SetLabelSize (0.03)\n",
    "    #hist_2d . GetZaxis (). SetNdivisions (512)\n",
    "    \n",
    "    hist_2d.Draw(\"colz\")\n",
    "    \n",
    "    \n",
    "    latex = ROOT . TLatex ()\n",
    "    latex . SetNDC ()\n",
    "    latex . SetTextSize (0.04)\n",
    "    #latex . DrawLatex (0.4 ,0.7, \"#Lambda_{Reconstructed} / #Lambda_{MC} =  %.f / %.f = %.3f\"%(sum(a),df4[df4['issignal']>0].shape[0], sum(a) / (df4[df4['issignal']>0].shape[0])))\n",
    "    latex . DrawLatex (0.12 ,0.65, \"Total Efficiency = #Lambda_{Reconstructed} / #Lambda_{Simulated} \" )\n",
    "\n",
    "    latex.Draw()\n",
    "\n",
    "    latex1 = ROOT . TLatex ()\n",
    "    latex1 . SetNDC ()\n",
    "    latex1 . SetTextSize (0.035)\n",
    "    latex1. DrawLatex (0.12 ,0.8, \"CBM performance\")\n",
    "    latex1. DrawLatex (0.12 ,0.75, \"DCM-QGSM-SMM, Au+Au @ 12#it{A} GeV/#it{c}\")\n",
    "    latex1 . DrawLatex (0.35 ,0.6, \"= %.f / %.f = %.3f\"%(sum_mc,sum(hist_2d_2), sum_mc / (sum(hist_2d_2))))\n",
    "    latex1.Draw()\n",
    "    c . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inFile = ROOT . TFile . Open ( \"new_urqmd_efficiency_pt_y_yield_bdt_cut_0.9.root\" ,\" READ \")\n",
    "inFile1 = ROOT . TFile . Open ( \"new_dcm_100_efficiency_pt_y_yield_bdt_cut_0.9.root\" ,\" READ \")\n",
    "inFile.ls()\n",
    "\n",
    "hist_2d = inFile1.Get(\"recons\")\n",
    "hist_2d_1 = inFile1.Get(\"Efficiency\")\n",
    "hist_2d_2 = inFile.Get(\"Mc_urqmd\")\n",
    "hist_2d_3 = inFile1.Get(\"recons\")\n",
    "\n",
    "\n",
    "\n",
    "#ROOT.gStyle.SetErrorX(0.);    \n",
    "sum_mc=sum(hist_2d)\n",
    "aaa = hist_2d.Divide(hist_2d_2)\n",
    "#bb = hist_2d.Divide(hist_2d_2)\n",
    "draw_2d_hist(hist_2d)\n",
    "#latex . DrawLatex (0.4 ,0.7, \"#Lambda_{Reconstructed} / #Lambda_{MC} =  %.f / %.f = %.3f\"%(sum(a),df4[df4['issignal']>0].shape[0], sum(a) / (df4[df4['issignal']>0].shape[0])))\n",
    "#latex . DrawLatex (0.35 ,0.35, \"X-axis Projection of URQMD 12AGeV AuAu\")\n",
    "#latex . DrawLatex (0.35 ,0.25, \"p_{T} = [%0.1f,%0.1f]\"%(hist_2d_3.GetYaxis().GetBinLowEdge(bin1), hist_2d_3.GetYaxis().GetBinUpEdge(bin2)))\n",
    "#x .GetXaxis().SetTitle(\"y_{Lab}\")\n",
    "#x .GetYaxis().SetTitle(\"Yield (log scale)\")\n",
    "#x .GetXaxis().SetTitleOffset(1)\n",
    "#x .GetYaxis().SetTitleOffset(0.4)\n",
    "#hist_2d .GetYaxis().SetTitle(\"p_{T} GeV/c\")\n",
    "#hist_2d .GetYaxis().SetTitleOffset(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, ROOT\n",
    "from ROOT import TF1, TCanvas,TMath, TColor\n",
    "\n",
    "\n",
    "inFile = ROOT . TFile . Open ( \"new_urqmd_efficiency_pt_y_yield_bdt_cut_0.9.root\" ,\" READ \")\n",
    "inFile1 = ROOT . TFile . Open ( \"new_dcm_100_efficiency_pt_y_yield_bdt_cut_0.9.root\" ,\" READ \")\n",
    "inFile.ls()\n",
    "\n",
    "hist_2d = inFile.Get(\"recons_urqmd\")\n",
    "hist_2d_1 = inFile1.Get(\"Efficiency\")\n",
    "hist_2d_2 = inFile.Get(\"Mc_urqmd\")\n",
    "#hist_2d_3 = inFile2.Get(\"reconstructable_mc\")\n",
    "\n",
    "\n",
    "canvas = ROOT . TCanvas (\" canvas \",\"\", 1000,700)\n",
    "canvas.Draw()\n",
    "#canvas.SetGrid()\n",
    "canvas.SetRightMargin(0.17);\n",
    "canvas.SetLeftMargin(0.17);\n",
    "canvas.SetBottomMargin(0.17);\n",
    "\n",
    "canvas.SetBorderSize(10);\n",
    "canvas.SetBorderMode(-1);\n",
    "\n",
    "sum_rec=sum(hist_2d)\n",
    "sum_ef=sum(hist_2d_1)\n",
    "\n",
    "hist_2d.SetStats(0)\n",
    "hist_2d.GetZaxis().SetRangeUser (0 ,1.1)\n",
    "#hist_2d.GetYaxis().SetRangeUser (0 ,3)\n",
    "\n",
    "aaa = hist_2d.Divide(hist_2d_1)\n",
    "bbb = hist_2d.Divide(hist_2d_2)\n",
    "\n",
    "\n",
    "hist_2d . SetTitle (\"\")\n",
    "hist_2d . GetXaxis() . SetTitle(\"#it{y}_{Lab}\")\n",
    "hist_2d . GetXaxis() . CenterTitle();\n",
    "hist_2d . GetXaxis() . SetTitleSize(0.06)\n",
    "hist_2d . GetXaxis() . SetTitleOffset(1.1)\n",
    "hist_2d . GetXaxis() . SetLabelSize(0.06)\n",
    "hist_2d . GetXaxis() . SetRangeUser(0.4,2.8)\n",
    "hist_2d . GetYaxis() . SetRangeUser(0,1.8)\n",
    "hist_2d . GetYaxis() . SetNdivisions(207)\n",
    "hist_2d . GetYaxis() . CenterTitle();\n",
    "hist_2d . GetYaxis() . SetTitle(\"p_{T} [GeV/#it{c}]\")\n",
    "hist_2d.  GetYaxis() . SetTitleSize(0.06)\n",
    "hist_2d . GetYaxis() . SetTitleOffset(0.8)\n",
    "hist_2d . GetYaxis() . SetLabelSize(0.05)\n",
    "hist_2d . GetZaxis() . SetLabelSize(0.05)\n",
    "hist_2d . GetZaxis() . SetNdivisions(512)\n",
    "hist_2d.Draw(\"colz\")\n",
    "\n",
    "latex = ROOT . TLatex ()\n",
    "latex . SetNDC ()\n",
    "latex . SetTextSize (0.035)\n",
    "latex. DrawLatex (0.18 ,0.85, \"CBM performance\")\n",
    "latex. DrawLatex (0.18 ,0.8, \"URQMD, Au+Au\")\n",
    "latex. DrawLatex (0.21 ,0.75, \"@ 12#it{A} GeV/#it{c}\")\n",
    "latex. DrawLatex (0.69 ,0.85, \"#Lambda hyperons\")\n",
    "#latex . DrawLatex (0.12 ,0.69, \"#frac{URQMD}{Efficiency DCM-QGSM-SMM} #frac{1}{Simulated #Lambda_{URQMD}} \" )\n",
    "\n",
    "#latex1 . DrawLatex (0.35 ,0.61, \"= %.f / %.f = %.3f\"%(sum_rec,sum_ef, sum_rec/ (sum_ef)))\n",
    "latex1.Draw()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "file =uproot.open(\"lambda_qa_dcm.root\")\n",
    "array1 = file[\"SimParticles_McLambda/SimParticles_rapidity_SimParticles_pT_McLambda\"].to_numpy()\n",
    "sum_mc = 0\n",
    "for i in range(0,15,1):\n",
    "array1[0][0][i]\n",
    "pt_y_yields['pt_y_yields_MC'].iloc[i+1*15]=array1[0][1][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file[\"urqmd_Efficiency\"].errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "#file =uproot.open(\"lambda_qa_urqmd.root\")\n",
    "#array1 = file[\"SimParticles_McLambda/SimParticles_rapidity_SimParticles_pT_McLambda\"].to_numpy()\n",
    "#for i in range(0,14,1):\n",
    "#array1[0][14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"0.png\",\"0.png\",\"0.png\",\"0.png\",\"10.png\",\"10.png\",\"10.png\",\"10.png\",\"20.png\",\"20.png\",\"20.png\",\"20.png\",\"40.png\",\"40.png\",\"40.png\",\"40.png\",\"80.png\",\"80.png\",\"80.png\",\"80.png\",\"test.png\",\"test.png\",\"test.png\",\"test.png\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for filename in filenames:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('movie.gif', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/cut_visualization/Lambda_XGB_prediction_0.jpg\",\n",
    "             \"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/cut_visualization/Lambda_XGB_prediction_0.1.jpg\",\n",
    "             \"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/cut_visualization/Lambda_XGB_prediction_0.2.jpg\",\n",
    "            \"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/cut_visualization/Lambda_XGB_prediction_0.4.jpg\",\n",
    "            \"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/cut_visualization/Lambda_XGB_prediction_0.8.jpg\",\n",
    "            \"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/cut_visualization/Lambda_XGB_prediction_0.96.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "with imageio.get_writer('movie.gif', mode='I',duration=2.5 ) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_signal = tree_importer('/home/shahid/Mount/gsi/u/flat_trees/PFSimplePlainTree_dcm_signal_1000k.root','PlainTree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"LambdaCandidates_chi2geo\", \"LambdaCandidates_chi2primneg\", \"LambdaCandidates_chi2primpos\",\n",
    "         \"LambdaCandidates_distance\", \"LambdaCandidates_ldl\",\"LambdaCandidates_mass\", \"LambdaCandidates_pT\",\n",
    "        \"LambdaCandidates_rapidity\", \"LambdaCandidates_is_signal\",\"LambdaCandidates_pz\",\"LambdaCandidates_p\",\n",
    "       \"LambdaCandidates_chi2topo\",\"LambdaCandidates_cosineneg\",\"LambdaCandidates_cosinepos\",\n",
    "        \"LambdaCandidates_eta\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = uproot.open('/home/shahid/Mount/gsi/u/flat_trees/PFSimplePlainTree_urqmd.root:PlainTree').arrays(labels,\"(LambdaCandidates_mass < 1.3) & (LambdaCandidates_mass > 1.07) & (LambdaCandidates_x>-50) & (LambdaCandidates_x<50) & (LambdaCandidates_y>-50) & (LambdaCandidates_y<50)& (LambdaCandidates_distance<100) & (LambdaCandidates_chi2geo>0)& (LambdaCandidates_chi2topo>0) & (LambdaCandidates_l<80)& (LambdaCandidates_chi2primpos>0) & (LambdaCandidates_chi2primneg > 0)\",library='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.DataFrame(data=file)\n",
    "df['LambdaCandidates_is_signal']=((df['LambdaCandidates_is_signal']>0)*1)\n",
    "with pd.option_context('mode.use_inf_as_na', True):\n",
    "    df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tree_importer('/home/shahid/Mount/gsi/u/flat_trees/PFSimplePlainTree_urqmd.root','PlainTree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels=['chi2geo', 'chi2primneg','chi2primpos', 'distance', 'ldl','mass', 'pT', 'rapidity','issignal','pz','p','chi2topo','cosineneg','cosinepos','eta']\n",
    "df.columns = new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_signal = df_clean_signal[df_clean_signal['issignal']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_signal = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import TFile, TTree\n",
    "from array import array\n",
    "from ROOT import std\n",
    "\n",
    "f = TFile('/media/shahid/KINGSTON/urqmd_100k.root','recreate')\n",
    "t = TTree('t1','tree with df')\n",
    "\n",
    "\n",
    "chi2geo = array('f',[0])\n",
    "chi2primneg = array('f',[0])\n",
    "chi2primpos = array('f',[0])\n",
    "distance = array('f',[0])\n",
    "ldl = array('f',[0])\n",
    "chi2topo=array('f',[0])\n",
    "cosineneg=array('f',[0])\n",
    "cosinepos=array('f',[0])\n",
    "mass = array('f',[0])\n",
    "p  = array('f',[0])\n",
    "pT = array('f',[0])\n",
    "pz = array('f',[0])\n",
    "#x = array('f',[0])\n",
    "#y = array('f',[0])\n",
    "eta = array('f',[0])\n",
    "rapidity = array('f',[0])\n",
    "issignal = array('f',[0])\n",
    "\n",
    "\n",
    "t.Branch('chi2geo', chi2geo,'chi2geo/F')\n",
    "t.Branch('chi2primneg', chi2primneg,'chi2primneg/F')\n",
    "t.Branch('chi2primpos', chi2primpos,'chi2primpos/F')\n",
    "t.Branch('distance', distance,'distance/F')\n",
    "t.Branch('ldl', ldl,'ldl/F')\n",
    "t.Branch('chi2topo', chi2topo,'chi2topo/F')\n",
    "t.Branch('cosineneg', cosineneg,'cosineneg/F')\n",
    "t.Branch('cosinepos', cosinepos,'cosinepos/F')\n",
    "t.Branch('mass', mass,'mass/F')\n",
    "t.Branch('p', p,'p/F')\n",
    "t.Branch('pT', pT,'pT/F')\n",
    "t.Branch('pz', pz,'pz/F')\n",
    "#t.Branch('x', x,'x/F')\n",
    "#t.Branch('y', y,'y/F')\n",
    "t.Branch('eta', eta,'eta/F')\n",
    "t.Branch('rapidity', rapidity,'rapidity/F')\n",
    "t.Branch('issignal', issignal,'issignal/F')\n",
    "\n",
    "for i in range(len(df_clean_signal['chi2geo'])):\n",
    "    chi2geo[0] = df_clean_signal['chi2geo'].iloc[i]\n",
    "    chi2primneg[0] = df_clean_signal['chi2primneg'].iloc[i]\n",
    "    chi2primpos[0] = df_clean_signal['chi2primpos'].iloc[i]\n",
    "    distance[0] = df_clean_signal['distance'].iloc[i]\n",
    "    ldl[0] = df_clean_signal['ldl'].iloc[i]\n",
    "    chi2topo[0] = df_clean_signal['chi2topo'].iloc[i]\n",
    "    cosineneg[0] = df_clean_signal['cosineneg'].iloc[i]\n",
    "    cosinepos[0] = df_clean_signal['cosinepos'].iloc[i]\n",
    "    mass[0] = df_clean_signal['mass'].iloc[i]\n",
    "    p[0] = df_clean_signal['p'].iloc[i]\n",
    "    pT[0] = df_clean_signal['pT'].iloc[i]\n",
    "    pz[0] = df_clean_signal['pz'].iloc[i]\n",
    "    #x[0] = df_clean_signal['x'].iloc[i]\n",
    "    #y[0] = df_clean_signal['y'].iloc[i]\n",
    "    eta[0] = df_clean_signal['eta'].iloc[i]\n",
    "    rapidity[0] = df_clean_signal['rapidity'].iloc[i]\n",
    "    issignal[0] = df_clean_signal['issignal'].iloc[i]\n",
    "    t.Fill()\n",
    "f.Write()\n",
    "f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/shahid/Mount/gsi/u/Mount/lustre/lubynets/cbm2atree/outputs/apr21_fr_18.2.1_fs_jun19p1/dcmqgsm_smm_pluto_w/auau/12agev/mbias/sis100_electron_apr20_target_25_mkm/TGeant4/1/1.analysistree.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = uproot.open(\"/home/shahid/Mount/gsi/u/Mount/lustre/lubynets/cbm2atree/outputs/apr21_fr_18.2.1_fs_jun19p1/dcmqgsm_smm_pluto_w/auau/12agev/mbias/sis100_electron_apr20_target_25_mkm/TGeant4/1/1.analysistree.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = file['aTree;1']\n",
    "a = tree['SimParticles']['channels_'].array(library='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.typenames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/cbmsoft/Cut_optimization/uncut_data/Project/fit/build/src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from ROOT import TF1, TCanvas,TMath, TColor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#df3 = uproot.open(\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pt_y_yield_bdt_cut_0.95.root:t1\").arrays(library='pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean =  uproot.open('dcm_prim_100k_cleaned.root:PlainTree').arrays(library='pd')\n",
    "signal = df_clean[ (df_clean['mass']>1.08)\n",
    "               & (df_clean['mass']<1.19)  & (df_clean['issignal']==1)]\n",
    "del df_clean\n",
    "df3 = signal[['mass', 'pT','rapidity', 'issignal']]\n",
    "del signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df3['mass'],bins=300)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ROOT.gInterpreter.ProcessLine('#include \"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/fit/src/AliHFMassFitter.h\"')\n",
    "ROOT.gInterpreter.ProcessLine('#include \"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/fit/src/AliLog.h\"')\n",
    "ROOT.gInterpreter.ProcessLine('#include \"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/fit/src/AliLog.cxx\"')\n",
    "ROOT.gInterpreter.ProcessLine('#include \"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/fit/src/AliHFMassFitter.cxx\"')\n",
    "ROOT.gSystem.Load(\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/fit/build/src/libSignalExtraction.so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter =  ROOT.AliHFMassFitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT.gInterpreter.Declare('''\n",
    "#if !defined(__CINT__) || defined(__MAKECINT__)\n",
    "#include <TCanvas.h>\n",
    "#include <TDatabasePDG.h>\n",
    "#include <TFile.h>\n",
    "#include <TH1F.h>\n",
    "#include <TH2F.h>\n",
    "#include <TMath.h>\n",
    "#include <TStyle.h>\n",
    "#include <TTree.h>\n",
    "\n",
    "// #include \"AliHFInvMassFitter.h\"\n",
    "// #include \"AliHFMassFitter.h\"\n",
    "#endif\n",
    "\n",
    "enum { kGaus = 0,\n",
    "  kDoubleGaus };\n",
    "  \n",
    "  Double_t minMassForFit = 1.08;\n",
    "  Double_t maxMassForFit = 1.2;\n",
    "  \n",
    "  //const Int_t nPtBins=5;\n",
    "  //Double_t ptlims[nPtBins+1]={1.,2.,3.,5.,8.,12.};\n",
    "  //Int_t rebin[nPtBins]={2,2,1,1,2};\n",
    "  const Int_t nPtBins = 15;\n",
    "  Double_t ptlims[nPtBins + 1] = {0., 3.};\n",
    "  Int_t rebin[nPtBins] = {2};\n",
    "  Int_t typeb = 2;\n",
    "  Int_t types = kGaus;\n",
    "  \n",
    "  using std::cout;\n",
    "  using std::endl; \n",
    "  void FitXicZerotoXiPiInvMass1(TString fname, TString fNameOut = \"\") {\n",
    "    \n",
    "    TFile* f = TFile::Open(fname.Data(), \"read\");\n",
    "    float mass;\n",
    "    \n",
    "    //   TBranch* bmass;\n",
    "    \n",
    "    TTree* t = f->Get<TTree>(\"t1\");\n",
    "    \n",
    "    t->SetBranchAddress(\"mass_branch\", &mass);\n",
    "    \n",
    "    \n",
    "    TH1F* hMass = new TH1F(\"hmass\", \"\", 200, 1.08, 1.2);\n",
    "    for (int i =0; i < t->GetEntries(); i++){\n",
    "      t->GetEntry(i);\n",
    "      hMass->Fill(mass);\n",
    "    }\n",
    "    AliHFMassFitter* fitter =  new AliHFMassFitter(hMass, minMassForFit, maxMassForFit, 1, typeb, types);\n",
    "\n",
    "   fitter->SetInitialGaussianMean(1.115);\n",
    "\n",
    "    //fitter->SetInitialGaussianSigma(0.001);\n",
    "    \n",
    "    \n",
    "\n",
    "    Bool_t ok = fitter->MassFitter(kFALSE);\n",
    "    auto* canvas = new TCanvas();\n",
    "    if (ok) {\n",
    "      fitter->DrawHere(canvas, 3, 1); \n",
    "    } else if (!ok) {\n",
    "      cout << \".........I am sorry\" << endl;\n",
    "      fitter->GetHistoClone()->Draw();\n",
    "    }\n",
    "    \n",
    "    \n",
    "  }\n",
    "  \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT.FitXicZerotoXiPiInvMass1(\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pt_y_yield_bdt_cut_0.95_new.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "f = ROOT.TFile('pt_y_yield_bdt_cut_0.95_new.root','recreate')\n",
    "t = ROOT.TTree('t1','tree with df')\n",
    "\n",
    "\n",
    "rapidity = array('f',[0])\n",
    "mass_branch = array('f',[0])\n",
    "pT_branch = array('f',[0])\n",
    "issignal = array('f',[0])\n",
    "\n",
    "t.Branch('rapidity', rapidity,'y/F')\n",
    "t.Branch('mass_branch', mass_branch,'mass_branch/F')\n",
    "t.Branch('pT_branch', pT_branch,'pT_branch/F')\n",
    "t.Branch('issignal', issignal,'issignal/F')\n",
    "\n",
    "for i in range(len(df3['mass'])):\n",
    "    mass_branch[0] = df3['mass'].iloc[i]\n",
    "    pT_branch[0] = df3['pT'].iloc[i]\n",
    "    issignal[0] = df3['issignal'].iloc[i]\n",
    "    rapidity[0] = df3['rapidity'].iloc[i]\n",
    "    t.Fill()\n",
    "f.Write()\n",
    "f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __call__( self, x, par ):\n",
    "        return par[0] + x[0]*par[1]\n",
    "\n",
    "fit_func = TF1('pyf3',Linear(),-1.,1.,2)\n",
    "\n",
    "class pol2:\n",
    "    def __call__( self, x, par ):\n",
    "        return par[0] + x[0]*par[1] + x[0]*par[1]*par[2]\n",
    "\n",
    "class lorenztian:\n",
    "    def _call_(self, x, p):\n",
    "        return 0.5*p[0]*p[1] /( ((x[0]-p[2])**2) + ((0.5 * (p[1])**2))) \n",
    "\n",
    "class gaus:\n",
    "    def _call_(self, x ,p):\n",
    "        return p[0]*np.exp(-0.5*((x[0]-p[2])/p[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def truncate(number, decimals=2):\n",
    "    \"\"\"\n",
    "    Returns a value truncated to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer.\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more.\")\n",
    "    elif decimals == 0:\n",
    "        return math.trunc(number)\n",
    "\n",
    "    factor = 10.0 ** decimals\n",
    "    return math.trunc(number * factor) / factor\n",
    "\n",
    "\n",
    "def background_selector(df):\n",
    "    df1 = df[(df['mass']<1.108)]\n",
    "    df2 = df[df['mass']>1.13]\n",
    "    df3 = pd.concat([df1, df2])\n",
    "    return df3['mass'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h1_set(h1):\n",
    "    h1 . SetTitleOffset(-1)\n",
    "    h1 . SetFillStyle(3003);\n",
    "    h1 . SetLineWidth(3)\n",
    "    h1 . SetStats (0)\n",
    "    h1 . SetYTitle(\"Counts\")\n",
    "    h1 . SetMarkerStyle(8)\n",
    "    h1 . SetMarkerSize(0.8)\n",
    "    h1 . SetLineColor (ROOT . kBlack)\n",
    "    #h1 . GetXaxis () . SetLabelSize (0)\n",
    "    #h1 . GetXaxis () . SetTitleSize (0)\n",
    "    h1 . GetYaxis () . SetTitleSize (0.05)\n",
    "    h1 . GetYaxis() . CenterTitle();\n",
    "    h1 . GetYaxis () . SetLabelSize (0.05)\n",
    "    h1 . GetYaxis () . SetTitleOffset (1)\n",
    "    h1 . GetYaxis () . SetNdivisions(107)\n",
    "    #h1 . GetYaxis () . SetRangeUser(0.8,100)\n",
    "    #h1 . GetXaxis () . SetRangeUser(1.105,1.13)\n",
    "    h1 . GetXaxis () . SetTitle(\"Mass (GeV/c^{2})\")\n",
    "    h1 . GetXaxis () . SetTitleOffset (1)\n",
    "    h1 . GetXaxis () . SetTitleSize (0.05)\n",
    "    #h1 . SetTitle (\"\")\n",
    "    return h1\n",
    "\n",
    "\n",
    "def h3_set(h3):   \n",
    "    h3 . SetLineWidth(3)\n",
    "    h3 . SetStats (0)\n",
    "    h3 . GetXaxis() . SetTitle(\"Mass (GeV/c^{2})\")\n",
    "    h3 . SetTitle (\"\")\n",
    "    h3 . GetXaxis () . SetLabelSize (0.15)\n",
    "    h3 . GetXaxis() . CenterTitle();\n",
    "    h3 . GetXaxis () . SetTitleSize (0.15)\n",
    "    h3 . GetYaxis () . SetLabelSize (0.15)\n",
    "    h3 . GetYaxis () . SetTitleSize (0.15)\n",
    "    h3 . GetXaxis () . SetTitleOffset (1.1)\n",
    "    h3 . GetYaxis () . SetTitleOffset (0.4)\n",
    "    #ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "    #207,512 divisions\n",
    "    h3 . GetYaxis (). SetNdivisions (104)\n",
    "    h3.SetLineColor(TColor.GetColor(5))\n",
    "    h3.SetYTitle(\"d-f/#Deltad\")\n",
    "    #h3 . GetXaxis () . SetRangeUser(1.105,1.13)\n",
    "    return h3\n",
    "\n",
    "\n",
    "def f_set(ftot, fs, fb):\n",
    "    ftot.SetNpx(100000);\n",
    "    ftot.SetLineColor(ROOT.kRed)\n",
    "    ftot.SetLineWidth(4)\n",
    "    \n",
    "    #fs.SetLineStyle(4)\n",
    "    fs.SetNpx(1000);\n",
    "    fs.SetLineColor(ROOT.kGreen)\n",
    "    fs.SetLineWidth(4)\n",
    "    fs.SetLineStyle(2);\n",
    "    fs.SetMarkerSize(2)\n",
    "    \n",
    "    fb.SetLineStyle(3)\n",
    "    fb.SetLineColor(ROOT.kBlue)\n",
    "    fb.SetNpx(100);\n",
    "    fb.SetLineWidth(4)\n",
    "    return ftot, fs, fb\n",
    "\n",
    "\n",
    "def draw_line():\n",
    "    line = ROOT . TLine (1.08,0 ,1.2 ,0)\n",
    "    line . SetLineColor ( ROOT . kRed )\n",
    "    line . SetLineWidth (2)\n",
    "    return line\n",
    "\n",
    "\n",
    "def draw_latex():\n",
    "    latex = ROOT . TLatex ()\n",
    "    latex . SetNDC ()\n",
    "    latex . SetTextSize (0.02)\n",
    "    #latex . DrawLatex (0.4 ,0.85, \"Significance in m_{0} #pm 2.5#Gamma  = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "    #latex . DrawLatex (0.4 ,0.80, \"Significance in m_{0} #pm 3#Gamma = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "    #latex . DrawLatex (0.4 ,0.75, \"Significance in m_{0} #pm 3.5#Gamma = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "    #latex . DrawLatex (0.4 ,0.70, \" #Gamma = %.4f #pm %.5f GeV\"%(par2 [1],f2.GetParError(1) ))\n",
    "    #latex . DrawLatex (0.4 ,0.85, \"Significance in m_{0} #pm 2.5#sigma  = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "    #latex . DrawLatex (0.4 ,0.80, \"Significance in m_{0} #pm 3#sigma = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "    #latex . DrawLatex (0.4 ,0.75, \"Significance in m_{0} #pm 3.5#sigma = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "    #latex . DrawLatex (0.17 ,0.80, \"#scale[1.5]{#sigma = %.4f #pm %.5f GeV}\"%(par2 [1],f2.GetParError(1) ))\n",
    "    #latex . DrawLatex (0.17 ,0.75, \"#scale[1.5]{#mu = %.4f #pm %.5f GeV}\"%(par2 [2],f2.GetParError(2) ))\n",
    "    #latex . DrawLatex (0.4 ,0.6,\" #frac{#chi^{2}}{ndf} = %.1f/%d = %.4f\"%(f2.GetChisquare() , f2.GetNDF() , f2.GetChisquare() / f2.GetNDF() ))\n",
    "    #latex . DrawLatex (0.4 ,0.55,\" True signal (MC=1) = %.f\"%(mc_counts))\n",
    "    #latex . DrawLatex (0.55 ,0.85, \"#scale[1.7]{CBM performance}\")\n",
    "    #latex . DrawLatex (0.65 ,0.8, \"#scale[1.7]{URQMD, Au+Au}\")\n",
    "    #latex . DrawLatex (0.65 ,0.75, \"#scale[1.7]{@ 12#it{A} GeV/#it{c}}\")\n",
    "    \n",
    "    #latex . DrawLatex (0.4 ,0.80, \"Significance in m_{0} #pm %.1f#sigma = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(sigma,signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,signal_under_peak/TMath.Sqrt(backgnd_under_peak+signal_under_peak) ))\n",
    "\n",
    "\n",
    "    return latex\n",
    "    \n",
    "    \n",
    "def draw_legend():\n",
    "    legend = ROOT.TLegend(0.55,0.5,0.9,0.9);\n",
    "    legend . AddEntry(h1,\"  #Lambda hyperons\",\"ep,X0\");\n",
    "    #legend . AddEntry(f2,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}+B+Cx+Dx^{2}\",\"l\");\n",
    "    #legend . AddEntry(fs,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}\",\"l\");\n",
    "    #legend.AddEntry(f2,\"Ae^{#frac{-1}{2} #frac{(x-1.115)^{2}}{0.0014^{2}}}+Be^{#frac{-1}{2} #frac{(x-1.115)^{2}}{0.01^{2}}}+pol2\",\"l\");\n",
    "    legend.AddEntry(f2,\"Ae^{#frac{-1}{2} #frac{(m-m_{0})^{2}}{#sigma^{2}}}+Be^{#frac{-1}{2} #frac{(m-m_{0})^{2}}{#sigma_{2}^{2}}}+pol2\",\"l\");\n",
    "\n",
    "    #legend.AddEntry(fs,\"Ae^{#frac{-1}{2} #frac{(m-m_{0})^{2}}{#sigma^{2}}}\",\"l\");\n",
    "\n",
    "    legend.AddEntry(fs,\"Ae^{#frac{-1}{2} #frac{(m-m_{0})^{2}}{#sigma^{2}}}+Be^{#frac{-1}{2} #frac{(m-m_{0})^{2}}{#sigma_{2}^{2}}}\",\"l\");\n",
    "    legend . AddEntry(fb,\"C+Dx+Ex^{2}\",\"l\");\n",
    "    legend . SetLineWidth (0)\n",
    "    legend . SetTextSize(0.033)\n",
    "    legend . SetBorderSize(0);\n",
    "    return legend\n",
    "\n",
    "\n",
    "def createCanvasPads():\n",
    "    c = ROOT . TCanvas (\" canvas \",\"\", 500,500)\n",
    "    \n",
    "    pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "    pad1 . SetBottomMargin (0)\n",
    "    pad1 . SetLeftMargin (0.15)\n",
    "    #pad1 . SetLogy()\n",
    "    pad1 . Draw ()\n",
    "    \n",
    "    pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "    pad2 . SetGrid()\n",
    "    pad2 . SetTopMargin (0)\n",
    "    pad2 . SetBottomMargin (0.5)\n",
    "    pad2 . SetLeftMargin (0.15)\n",
    "    pad2 . Draw ()\n",
    "    return c, pad1, pad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import root_functions\n",
    "from root_functions import truncate, background_selector, f_set, draw_latex, draw_legend, createCanvasPads, draw_hist, signal_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hist(h1, f2, fs, fb, h3):\n",
    "    ROOT . gStyle . SetFillColor(-1);\n",
    "    ROOT . gStyle . SetFillStyle(4000);\n",
    "    ROOT . gStyle . SetLegendBorderSize(0);\n",
    "    ROOT . gStyle . SetFrameBorderSize(0);\n",
    "    ROOT . gStyle . SetFrameFillColor(-1);\n",
    "    c, pad1, pad2 = createCanvasPads ()\n",
    "    c . Draw ()\n",
    "    pad1 . cd ()\n",
    "    #pad1 . SetLogy()\n",
    "    \n",
    "    h1 = h1_set (h1)\n",
    "    #h1 = ROOT . h1_set (h1)\n",
    "    f2, fs, fb = f_set (f2, fs, fb)\n",
    "    \n",
    "    h1 . Draw(\"pe,X0\")\n",
    "    fb . Draw(\"SAME\")\n",
    "    f2 . Draw(\"SAME\") #use ESAME for bands\n",
    "    fs . Draw(\"SAME\")\n",
    "    draw_latex()\n",
    "    legend = draw_legend ()\n",
    "    legend . Draw()\n",
    "    \n",
    "    c . cd ()\n",
    "    pad2 . cd ()\n",
    "    \n",
    "    h3_set(h3) . Draw()\n",
    "    #h3 = ROOT . h3_set(h3)\n",
    "    h3 . Draw()\n",
    "    \n",
    "    line = draw_line ()\n",
    "    #line = ROOT . draw_line (line = ROOT . TLine (1.105,0 ,1.13 ,0))\n",
    "    line . Draw (\" same \")\n",
    "    c . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")    \n",
    "    #c . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special as ss\n",
    "ss.erf(2/np.sqrt(2))\n",
    "(2/np.pi)* np.arctan(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_cal(h, f_tot, fs, fb, sigma):\n",
    "    tot_sig_sigma, tot_bac_sigma = 0, 0   \n",
    "    \n",
    "    binwidth = h.GetXaxis().GetBinWidth(1);\n",
    "    tot = f_tot.Integral(par2[2] - (TMath.Abs(sigma*par2[1])),par2[2] + (TMath.Abs(sigma*par2[1])))/binwidth;\n",
    "    sigma_integral = f_tot.IntegralError(par2[2] - (TMath.Abs(sigma*par2[1])),par2[2] + (TMath.Abs(sigma*par2[1])));\n",
    "    #params.integral = fit->GetParameter(0) * sqrt(2*3.1415) * fit->GetParameter(2) / h->GetBinWidth(1);\n",
    "    #signal_under_peak = par2[1] * np.sqrt(2*3.1415) *3 *par2[2]/ binwidth\n",
    "    signal_under_peak = fs.Integral(par2[2] - (TMath.Abs(sigma*par2[1])),par2[2] + (TMath.Abs(sigma*par2[1])))/binwidth\n",
    "               \n",
    "    sigma_signal_under_peak = fs.IntegralError(par2[2] - (TMath.Abs(sigma*par2[1])),par2[2] + (TMath.Abs(sigma*par2[1])));\n",
    "    man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "\n",
    "\n",
    "    tot_sig_sigma= tot_sig_sigma+signal_under_peak\n",
    "#Background\n",
    "    backgnd_under_peak = (fb.Integral(par2[2] - (TMath.Abs(sigma*par2[1])),par2[2] + (TMath.Abs(sigma*par2[1])))/binwidth)\n",
    "\n",
    "    sigma_backgnd_under_peak = fb.IntegralError(par2[2] - (TMath.Abs(sigma*par2[1])),par2[2] + (TMath.Abs(sigma*par2[1])));\n",
    "    tot_bac_sigma = tot_bac_sigma+backgnd_under_peak\n",
    "#Significance = signal/(signal+background)^0.5\n",
    "    Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "  \n",
    "    return tot, signal_under_peak, man_sigma_signal_under_peak,tot_sig_sigma, backgnd_under_peak, Significance, sigma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2000000000*0.947 / 15633824\n",
    "                        #f1 = TF1(\"fitFcn\", \"TMath::Voigt(x - 1.115,[0], 0.0004, 4)+[1]+[2]*x+[3]*x*x\", fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #f1.SetParameters(0.0001,par[0], par[1], par[2]);\n",
    "\n",
    "\n",
    "\n",
    "                        #f2 = TF1(\"fitFcn\", \"TMath::Voigt(x - [0], [1], [2], 4)+[3]+[4]*x+[5]*x*x\", fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #f2.SetParameters(1.115,par1[0],0.0004, par1[1], par1[2],par1[3]);\n",
    "                        r= ROOT.TFitResultPtr(h1.Fit(f2,\"MNR\"))\n",
    "                        par2 = f2.GetParameters()\n",
    "\n",
    "                        fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)+[3]*exp(-0.5*((x-[5])/[4])^2)\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        #fs = TF1(\"fitFcn\", \"TMath::Voigt(x - [0], [1], [2], 4)\", fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        fs.SetParameters(par2[0],par2[1],par2[2],par2[3],par2[4],par2[5]);\n",
    "                        fb.SetParameters(par2[6],par2[7],par2[8]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import AliHFInvMassFitter\n",
    "import time\n",
    "starttime = time.time()\n",
    "c = ROOT . TCanvas (\" canvas \",\"\", 500,500)\n",
    "\n",
    "a = []\n",
    "pt_y_bin_for_yield_min=[]\n",
    "pt_y_bin_for_yield_max=[]\n",
    "y_bin_for_yield_max=[]\n",
    "y_bin_for_yield_min=[]\n",
    "true_mc_in_recons =[]\n",
    "red_chi = []\n",
    "\n",
    "df = df3\n",
    "mass_range_min = [1.08]\n",
    "fit_limit_low=[0,0.1* (df['mass'].describe()[2]),   0.2* (df['mass'].describe()[2]),\n",
    "               1.23,\n",
    "               df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.1* (df['mass'].describe()[2]),\n",
    "                df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.2* (df['mass'].describe()[2])]\n",
    "\n",
    "\n",
    "for mm in mass_range_min:\n",
    "    for mmm in range(0,1,1):\n",
    "\n",
    "        binning = [160]\n",
    "        for b in binning:\n",
    "\n",
    "            y_bin_low=-0.2\n",
    "            y_bin_up =0\n",
    "            j=0\n",
    "            for i in range(0,15,1):\n",
    "                j=j+1\n",
    "                tot_sig_3_point_5_sigma, tot_sig_3_sigma, tot_sig_2_point_5_sigma, tot_sig_2_sigma = 0, 0, 0, 0\n",
    "                tot_bac_3_sigma, tot_bac_3_point_5_sigma, tot_bac_2_point_5_sigma = 0, 0, 0\n",
    "                #Divide the data into 15*15 pT-y bins\n",
    "                y_bin_low = truncate(y_bin_low+0.2)\n",
    "                y_bin_up = truncate(y_bin_up+0.2)\n",
    "                df_y = df[(df['rapidity']>y_bin_low) & (df['rapidity']<y_bin_up)]\n",
    "                pt_bin_low =-0.2\n",
    "                pt_bin_up =0\n",
    "                \n",
    "                for i in range(0,15,1):\n",
    "                    pt_bin_low = truncate(pt_bin_low+0.2)\n",
    "                    #print(pt_bin_low)\n",
    "                    pt_bin_up = truncate(pt_bin_up+0.2)\n",
    "                    df_pt = df_y[(df_y['pT']>pt_bin_low) & (df_y['pT']<pt_bin_up)]\n",
    "                    mc_counts = df_pt[df_pt['issignal']>0].shape[0]\n",
    "                    #print(y_bin_low, y_bin_up, \" pT \", pt_bin_low,pt_bin_up)\n",
    "                    #if a bin has more than 200 counts only then try to follow the fit procedure\n",
    "                    if df_pt.shape[0]>3000:\n",
    "                        #take the histogram and remove the main lambda peak region and fit the rest with a pol2\n",
    "                        data0 = background_selector(df_pt)\n",
    "                        h0 = ROOT.TH1F(\"Background\",\"Background without peak\",b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data0.shape[0]):\n",
    "                            h0.Fill(data0.iloc[i])\n",
    "                        fb = TF1(\"fb\",\"pol2\",h0.GetMean()-1*(h0.GetRMS()),h0.GetMean()+1*(h0.GetRMS()));\n",
    "                        #h0.Fit(fb,\"RMNI\",\"L\",h0.GetMean()-1*(h0.GetRMS()),h0.GetMean()+1*(h0.GetRMS()));\n",
    "                        #par = fb.GetParameters()\n",
    "                        data = df_pt['mass']\n",
    "                        \n",
    "                #the minimum x (lower edge of the first bin)=mm        \n",
    "                        h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(df_pt['rapidity'].min(),df_pt['rapidity'].max(),df_pt['pT'].min(),df_pt['pT'].max(), mm, b),b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data.shape[0]):\n",
    "                            h1.Fill(data.iloc[i])\n",
    "                                   \n",
    "\n",
    "                        fitter0 = AliHFInvMassFitter(h1, 1.08, 1.2,   AliHFInvMassFitter.ETypeOfBkg.kPol2, AliHFInvMassFitter.ETypeOfSgn.k2Gaus);\n",
    "                        fitter0.SetInitialGaussianMean(1.1156);\n",
    "                        fitter0.SetInitialGaussianSigma(0.0009);\n",
    "                        #fitter0->SetInitialFrac2Gaus(0.2);\n",
    "                        fitter0.SetInitialSecondGaussianSigma(0.0009);\n",
    "                        \n",
    "                        fitter0.MassFitter()\n",
    "                        \n",
    "                        M_func = fitter0.GetMassFunc()\n",
    "                        h1 = h1_set (h1)\n",
    "                        c.Draw()\n",
    "                        h1 . Draw(\"pe,X0\")\n",
    "                        #M_func.Draw(\"SAME\")\n",
    "                        c . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cpproot_time = time.time() - starttime\n",
    "print(f\"total time: {cpproot_time} sec\")\n",
    "c . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "starttime = time.time()\n",
    "\n",
    "a = []\n",
    "pt_y_bin_for_yield_min=[]\n",
    "pt_y_bin_for_yield_max=[]\n",
    "y_bin_for_yield_max=[]\n",
    "y_bin_for_yield_min=[]\n",
    "true_mc_in_recons =[]\n",
    "red_chi = []\n",
    "\n",
    "df = df3\n",
    "mass_range_min = [1.08]\n",
    "fit_limit_low=[0,0.1* (df['mass'].describe()[2]),   0.2* (df['mass'].describe()[2]),\n",
    "               1.23,\n",
    "               df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.1* (df['mass'].describe()[2]),\n",
    "                df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.2* (df['mass'].describe()[2])]\n",
    "\n",
    "\n",
    "for mm in mass_range_min:\n",
    "    for mmm in range(0,1,1):\n",
    "\n",
    "        binning = [160]\n",
    "        for b in binning:\n",
    "\n",
    "            y_bin_low=-0.2\n",
    "            y_bin_up =0\n",
    "            for i in range(0,15,1):\n",
    "                tot_sig_3_point_5_sigma, tot_sig_3_sigma, tot_sig_2_point_5_sigma, tot_sig_2_sigma = 0, 0, 0, 0\n",
    "                tot_bac_3_sigma, tot_bac_3_point_5_sigma, tot_bac_2_point_5_sigma = 0, 0, 0\n",
    "                #Divide the data into 15*15 pT-y bins\n",
    "                y_bin_low = truncate(y_bin_low+0.2)\n",
    "                y_bin_up = truncate(y_bin_up+0.2)\n",
    "                df_y = df[(df['rapidity']>y_bin_low) & (df['rapidity']<y_bin_up)]\n",
    "                pt_bin_low =-0.2\n",
    "                pt_bin_up =0\n",
    "                \n",
    "                for i in range(0,15,1):\n",
    "                    pt_bin_low = truncate(pt_bin_low+0.2)\n",
    "                    #print(pt_bin_low)\n",
    "                    pt_bin_up = truncate(pt_bin_up+0.2)\n",
    "                    df_pt = df_y[(df_y['pT']>pt_bin_low) & (df_y['pT']<pt_bin_up)]\n",
    "                    mc_counts = df_pt[df_pt['issignal']>0].shape[0]\n",
    "                    #print(y_bin_low, y_bin_up, \" pT \", pt_bin_low,pt_bin_up)\n",
    "                    #if a bin has more than 200 counts only then try to follow the fit procedure\n",
    "                    if df_pt.shape[0]>3000:\n",
    "                        #take the histogram and remove the main lambda peak region and fit the rest with a pol2\n",
    "                        data0 = background_selector(df_pt)\n",
    "                        h0 = ROOT.TH1F(\"Background\",\"Background without peak\",b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data0.shape[0]):\n",
    "                            h0.Fill(data0.iloc[i])\n",
    "                        fb = TF1(\"fb\",\"pol2\",h0.GetMean()-1*(h0.GetRMS()),h0.GetMean()+1*(h0.GetRMS()));\n",
    "                        h0.Fit(fb,\"RMNI\",\"L\",h0.GetMean()-1*(h0.GetRMS()),h0.GetMean()+1*(h0.GetRMS()));\n",
    "                        par = fb.GetParameters()\n",
    "                        data = df_pt['mass']\n",
    "                        \n",
    "                #the minimum x (lower edge of the first bin)=mm        \n",
    "                        h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(df_pt['rapidity'].min(),df_pt['rapidity'].max(),df_pt['pT'].min(),df_pt['pT'].max(), mm, b),b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data.shape[0]):\n",
    "                            h1.Fill(data.iloc[i])\n",
    "                        \n",
    "                        #make a double gaussian but fix the width and mean parameter\n",
    "                        f1 = TF1(\"step1\",\"[0]*exp(-0.5*((x-1.115683)/0.001)^2)+[1]*exp(-0.5*((x-1.115683)/0.004)^2) +[2]+[3]*x+[4]*x*x\",h1.GetMean()-1*(h1.GetRMS()),h1.GetMean()+1*(h1.GetRMS()));\n",
    "                        f1.SetParameters(1,1,par[0], par[1], par[2]); \n",
    "                        h1.Fit(f1,\"RNI\",\"L\",h1.GetMean()-1*(h1.GetRMS()),h1.GetMean()+1*(h1.GetRMS()));\n",
    "                        #save the fit parameters and use them as initial parameters\n",
    "                        par1 = f1.GetParameters()\n",
    "                        #now take h1 again but this time fit it with a double gaussian but leave all fit parameters unconstrained\n",
    "                        f2 = TF1(\"full\",\"[0]*exp(-0.5*((x-[2])/[1])^2)+[3]*exp(-0.5*((x-[2])/[4])^2) +[5]+[6]*x+[7]*x*x\",h1.GetMean()-1*(h1.GetRMS()),h1.GetMean()+1*(h1.GetRMS()))\n",
    "                        f2.SetParameters(par1[0],0.001,1.114,par1[1],0.004,par1[2], par1[3],par1[4])\n",
    "                        \n",
    "\n",
    "                        r= ROOT.TFitResultPtr(h1.Fit(f2,\"MNRI\",\"L\",h1.GetMean()-1*(h1.GetRMS()),h1.GetMean()+1*(h1.GetRMS())))\n",
    "                        #save the fit parameters and use them as initial parameters\n",
    "                        par2 = f2.GetParameters()\n",
    "\n",
    "                        fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)+[3]*exp(-0.5*((x-[2])/[4])^2)\",h1.GetMean()-1*(h1.GetRMS()),h1.GetMean()+1*(h1.GetRMS()));\n",
    "                        #fs = TF1(\"fitFcn\", \"TMath::Voigt(x - [0], [1], [2], 4)\", fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        fs.SetParameters(par2[0],par2[1],par2[2],par2[3],par2[4]);\n",
    "                        fb.SetParameters(par2[5],par2[6],par2[7]);\n",
    "                        \n",
    "\n",
    "\n",
    "                        h2 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        h3 = ROOT.TH1F(\"h3\", \"\", b, mm, 1.23);\n",
    "\n",
    "\n",
    "                        bin1 = h1.FindBin(h1.GetMean()-1*(h1.GetRMS()));\n",
    "                        bin2 = h1.FindBin(h1.GetMean()+1*(h1.GetRMS()));\n",
    "                        for i in range(bin1,bin2):\n",
    "                            f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                            t_value = h1.GetBinContent(i)\n",
    "                            h2.SetBinContent(i,f_value)\n",
    "                            if (h1.GetBinError(i) > 0):\n",
    "                                h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "                        h2.Sumw2()\n",
    "\n",
    "                        tot, signal_under_peak, man_sigma_signal_under_peak,tot_sig_sigma, backgnd_under_peak, Significance, sigma= signal_cal(h1, f2, fs, fb,3)\n",
    "\n",
    "                        \n",
    "                        c = draw_hist(h1, f2, fs, fb, h3)\n",
    "                        \n",
    "                        \n",
    "            #a.append(tot_sig_2_point_5_sigma)\n",
    "                        if f2.GetNDF()!= 0:\n",
    "                            red_chi.append(f2.GetChisquare() / f2.GetNDF() )\n",
    "                        else:\n",
    "                            red_chi.append(0)\n",
    "                        #a.append(signal_under_peak_2_sigma)\n",
    "                        #a.append(signal_under_peak_2_point_5_sigma)\n",
    "                        a.append(signal_under_peak)\n",
    "                        #a.append(signal_under_peak_3_point_5_sigma)\n",
    "                        y_bin_for_yield_min.append(truncate(y_bin_low))\n",
    "                        y_bin_for_yield_max.append(truncate(y_bin_up))\n",
    "                        pt_y_bin_for_yield_min.append(pt_bin_low)\n",
    "                        pt_y_bin_for_yield_max.append(pt_bin_up)\n",
    "                        true_mc_in_recons.append(mc_counts)\n",
    "                    else:\n",
    "                        a.append(0)\n",
    "                        red_chi.append(0)\n",
    "                        y_bin_for_yield_min.append(truncate(y_bin_low))\n",
    "                        y_bin_for_yield_max.append(truncate(y_bin_up))\n",
    "                        pt_y_bin_for_yield_min.append(pt_bin_low)\n",
    "                        pt_y_bin_for_yield_max.append(pt_bin_up)\n",
    "                        true_mc_in_recons.append(mc_counts)\n",
    "\n",
    "\n",
    "cpproot_time = time.time() - starttime\n",
    "print(f\"total time: {cpproot_time} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p4)/len(p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2000/(22000+24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = -5, 14, -9.81\n",
    "x = np.linspace(1.08,1.22,20)\n",
    "fb = a+b*x+c*x*x\n",
    "plt.plot(x,fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pikepdf\n",
    "import os\n",
    "\n",
    "def changefile (file):\n",
    "    print(\"Processing {0}\".format(file))\n",
    "    pdf = pikepdf.Pdf.open(file)\n",
    "    lastPageNum = len(pdf.pages)\n",
    "    pdf.pages.remove(p = lastPageNum)\n",
    "    pdf.save(file + '.tmp')\n",
    "    pdf.close()\n",
    "    os.unlink(file)\n",
    "    os.rename(file + '.tmp', file)\n",
    "\n",
    "for file in os.listdir(\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/\"):\n",
    "    if file.lower().endswith(\"pT_rapidity_distribution_XGB_extracted_signal.pdf\"):\n",
    "        changefile(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(red_chi)\n",
    "28.64717633010704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import wofz\n",
    "import pylab\n",
    "\n",
    "def G(x, alpha):\n",
    "    \"\"\" Return Gaussian line shape at x with HWHM alpha \"\"\"\n",
    "    return np.sqrt(2* np.pi) / alpha\\\n",
    "                             * np.exp(-(x -1.115/ alpha)**2 * 2)\n",
    "\n",
    "def L(x, gamma):\n",
    "    \"\"\" Return Lorentzian line shape at x with HWHM gamma \"\"\"\n",
    "    return gamma / np.pi / ((x-1.115)**2 + gamma**2)\n",
    "\n",
    "def V(x, alpha, gamma):\n",
    "    \"\"\"\n",
    "    Return the Voigt line shape at x with Lorentzian component HWHM gamma\n",
    "    and Gaussian component HWHM alpha.\n",
    "\n",
    "    \"\"\"\n",
    "    sigma = alpha / np.sqrt(2 * np.log(2))\n",
    "\n",
    "    return np.real(wofz((x-1.115 + 1j*gamma)/sigma/np.sqrt(2))) / sigma\\\n",
    "                                                           /np.sqrt(2*np.pi)\n",
    "\n",
    "alpha, gamma = 0.0001, 0.0004\n",
    "x = np.linspace(1.05,1.22,1000)\n",
    "pylab.plot(x, G(x, alpha), ls=':', label='Gaussian')\n",
    "#pylab.plot(x, L(x, gamma), ls='--', label='Lorentzian')\n",
    "pylab.plot(x, V(x, alpha, gamma), label='Voigt')\n",
    "pylab.xlim(1.105,1.13)\n",
    "pylab.legend()\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11.690671682357788 sec\n",
    "11.278231620788574 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal\n",
    "a = []\n",
    "pt_y_bin_for_yield_min=[]\n",
    "pt_y_bin_for_yield_max=[]\n",
    "y_bin_for_yield_max=[]\n",
    "y_bin_for_yield_min=[]\n",
    "true_mc_in_recons =[]\n",
    "red_chi = []\n",
    "\n",
    "\n",
    "df = df3\n",
    "mass_range_min = [1.08]\n",
    "fit_limit_low=[0,0.1* (df['mass'].describe()[2]),   0.2* (df['mass'].describe()[2]),\n",
    "               1.23,\n",
    "               df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.1* (df['mass'].describe()[2]),\n",
    "                df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.2* (df['mass'].describe()[2])]\n",
    "\n",
    "\n",
    "for mm in mass_range_min:\n",
    "    for mmm in range(0,1,1):\n",
    "\n",
    "        binning = [100]\n",
    "        for b in binning:\n",
    "\n",
    "            y_bin_low=-0.2\n",
    "            y_bin_up =0\n",
    "            for i in range(0,15,1):\n",
    "                tot_sig_3_point_5_sigma, tot_sig_3_sigma, tot_sig_2_point_5_sigma, tot_sig_2_sigma = 0, 0, 0, 0\n",
    "                tot_bac_3_sigma, tot_bac_3_point_5_sigma, tot_bac_2_point_5_sigma = 0, 0, 0\n",
    "\n",
    "                \n",
    "                y_bin_low = truncate(y_bin_low+0.2)\n",
    "                y_bin_up = truncate(y_bin_up+0.2)\n",
    "                df_y = df[(df['rapidity']>y_bin_low) & (df['rapidity']<y_bin_up)]\n",
    "                pt_bin_low =-0.2\n",
    "                pt_bin_up =0\n",
    "                \n",
    "                for i in range(0,15,1):\n",
    "                    pt_bin_low = truncate(pt_bin_low+0.2)\n",
    "                    #print(pt_bin_low)\n",
    "                    pt_bin_up = truncate(pt_bin_up+0.2)\n",
    "                    df_pt = df_y[(df_y['pT']>pt_bin_low) & (df_y['pT']<pt_bin_up)]\n",
    "                    mc_counts = df_pt[df_pt['issignal']>0].shape[0]\n",
    "                    #print(y_bin_low, y_bin_up, \" pT \", pt_bin_low,pt_bin_up)\n",
    "                    if df_pt.shape[0]>200:\n",
    "                        data = df_pt[df_pt['issignal']==1]['mass']\n",
    "                        \n",
    "                #the minimum x (lower edge of the first bin)=mm        \n",
    "                        h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(df_pt['rapidity'].min(),df_pt['rapidity'].max(),df_pt['pT'].min(),df_pt['pT'].max(), mm, b),b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data.shape[0]):\n",
    "                            h1.Fill(data.iloc[i])\n",
    "                        \n",
    "                        #f2 = TF1(\"fs\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1])\",h1.GetMean()-3*(h1.GetRMS()),h1.GetMean()+3*(h1.GetRMS()))\n",
    "                        #f2.SetParameters(1,0.001,1.115)\n",
    "                        #f2 = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)\",h1.GetMean()-3.5*(h1.GetRMS()),h1.GetMean()+3.5*(h1.GetRMS()))\n",
    "                        #f2.SetParameters(1,0.006,1.114)\n",
    "                        #double gaussian\n",
    "                        f2 = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)+[3]*exp(-0.5*((x-[2])/[4])^2) \",h1.GetMean()-3.5*(h1.GetRMS()),h1.GetMean()+3.5*(h1.GetRMS()))\n",
    "                        f2.SetParameters(10,0.001,1.114,1,0.01)\n",
    "                        \n",
    "                        #f4 = TF1(\"fitFcn\", \"TMath::Voigt(x - [0], [1], [2], 4)\", h1.GetMean()-3.5*(h1.GetRMS()),h1.GetMean()+3.5*(h1.GetRMS()))\n",
    "                        #f4.SetParameters(1.115,0.01,0.0004);\n",
    "\n",
    "\n",
    "                        \n",
    "                        #f2 = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)+[3]*exp(-0.5*((x-[5])/[4])^2)\",h1.GetMean()-3.5*(h1.GetRMS()),h1.GetMean()+3.5*(h1.GetRMS()))\n",
    "                        #f2.SetParameters(1,0.006,1.114,1,0.01,1.114)\n",
    "                        \n",
    "                        #h1.Fit(f2,\"IMNR\")\n",
    "                        #par2 = f2.GetParameters()\n",
    "                        h1.Fit(f2,\"IMNR\")\n",
    "                        par2 = f2.GetParameters()\n",
    "                        #h1.Fit(f4,\"IMNR\")\n",
    "                        #par4= f4.GetParameters()\n",
    "                        \n",
    "\n",
    "                        #fs = TF1(\"fs\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1])\",h1.GetMean()-3*(h1.GetRMS()),h1.GetMean()+3*(h1.GetRMS()))\n",
    "                        #fs= TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)+[3]*exp(-0.5*((x-[5])/[4])^2)\",h1.GetMean()-3.5*(h1.GetRMS()),h1.GetMean()+3.5*(h1.GetRMS()))\n",
    "                        #fs.SetParameters(par2[0],par2[1],par2[2],par2[3],par2[4],par2[5]);\n",
    "                        #fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)\",h1.GetMean()-3.5*(h1.GetRMS()),h1.GetMean()+3.5*(h1.GetRMS()))\n",
    "                        #fs.SetParameters(par2[0],par2[1],par2[2]);\n",
    "                        #double gaussian\n",
    "                        fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)+[3]*exp(-0.5*((x-[2])/[4])^2) \",h1.GetMean()-3.5*(h1.GetRMS()),h1.GetMean()+3.5*(h1.GetRMS()))\n",
    "                        fs . SetParameters(par3[0],par3[1],par3[2],par3[3],par3[4])\n",
    "                        fs . SetNpx(100000);\n",
    "                        fs . SetLineColor(ROOT.kBlue)\n",
    "                        \n",
    "                        #fs2 = TF1(\"fitFcn\", \"TMath::Voigt(x - [0], [1], [2], 4)\", h1.GetMean()-3.5*(h1.GetRMS()),h1.GetMean()+3.5*(h1.GetRMS()))\n",
    "                        #fs2 . SetParameters(par4[0],par4[1],par4[2]);\n",
    "                        #fs2 . SetNpx(100000);\n",
    "                        #fs2 . SetLineColor(ROOT.kGreen)\n",
    "\n",
    "\n",
    "                        h2 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        h3 = ROOT.TH1F(\"h3\", \"\", b, mm, 1.23);\n",
    "                        \n",
    "                        #h4 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        #h5 = ROOT.TH1F(\"h3\", \"\", b, mm, 1.23);\n",
    "\n",
    "\n",
    "                        bin1 = h1.FindBin(fit_limit_low[mmm]+mm);\n",
    "                        bin2 = h1.FindBin(fit_limit_low[mmm+3]);\n",
    "                        for i in range(bin1,bin2):\n",
    "                            f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                            t_value = h1.GetBinContent(i)\n",
    "                            h2.SetBinContent(i,f_value)\n",
    "                            if (h1.GetBinError(i) > 0):\n",
    "                                h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "                            \n",
    "                            #f_value1= f3.Eval(h1.GetBinCenter(i));\n",
    "                            #h4.SetBinContent(i,f_value1)\n",
    "                            #if (h1.GetBinError(i) > 0):\n",
    "                            #    h5.SetBinContent(i,(t_value-f_value1)/h1.GetBinError(i))\n",
    "\n",
    "                        h2.Sumw2()\n",
    "                        #h4.Sumw2()\n",
    "\n",
    "                    #To integrate area under the signal plus background curve we take 3 sigma and integrate\n",
    "                        binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "                        signal_under_peak = fs.Integral(par2[2] - (TMath.Abs(3*par2[1])),par2[2] + (TMath.Abs(3*par2[1])))/binwidth\n",
    "                        if signal_under_peak<0:\n",
    "                            signal_under_peak = 0\n",
    "                            print('Negative signal')                \n",
    "                        sigma_signal_under_peak = fs.IntegralError(par2[2] - (TMath.Abs(3*par2[1])),par2[2] + (TMath.Abs(3*par2[1])));\n",
    "                        man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "\n",
    "                        #3.5 sigma\n",
    "                        signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        #bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        tot_sig_3_point_5_sigma = tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma\n",
    "                        #tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "                        sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "                        man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "                        signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        #bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "                        #tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "                        sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "                        man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "                        signal_under_peak_2_sigma = (fs.Integral(par2[2] - (TMath.Abs(2*par2[1])),par2[2] + (TMath.Abs(2*par2[1])))/binwidth);\n",
    "                        \n",
    "                        c, pad1, pad2 = createCanvasPads ()\n",
    "                        c . Draw ()\n",
    "                        pad1 . cd ()\n",
    "\n",
    "                        h1 = h1_set (h1)\n",
    "                        h1.Draw(\"pe\")\n",
    "                        #fs . Draw(\"SAME\")\n",
    "                        fs1. Draw(\"SAME\")\n",
    "                        #fs2. Draw(\"SAME\") \n",
    "                        draw_latex()\n",
    "                        legend = draw_legend ()\n",
    "                        legend . Draw()\n",
    "                        \n",
    "\n",
    "                        c . cd ()\n",
    "                        pad2 . cd ()\n",
    "                        h3_set(h3) . Draw()\n",
    "                        \n",
    "\n",
    "\n",
    "                        #line = ROOT . draw_line (line = ROOT . TLine (mm,0 ,1.23 ,0))\n",
    "                        #line . Draw (\" same \")    \n",
    "                        c . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "\n",
    "                        del h1,h2,h3\n",
    "                        \n",
    "            #a.append(tot_sig_2_point_5_sigma)\n",
    "                        #a.append(signal_under_peak_2_sigma)\n",
    "                        a.append(signal_under_peak_2_point_5_sigma)\n",
    "                        if f2.GetNDF()!= 0:\n",
    "                            red_chi.append(f2.GetChisquare() / f2.GetNDF() )\n",
    "                        else:\n",
    "                            red_chi.append(0)\n",
    "\n",
    "                        #a.append(signal_under_peak)\n",
    "                        #a.append(signal_under_peak_3_point_5_sigma)\n",
    "                        y_bin_for_yield_min.append(truncate(y_bin_low))\n",
    "                        y_bin_for_yield_max.append(truncate(y_bin_up))\n",
    "                        pt_y_bin_for_yield_min.append(pt_bin_low)\n",
    "                        pt_y_bin_for_yield_max.append(pt_bin_up)\n",
    "                        true_mc_in_recons.append(mc_counts)\n",
    "                    else:\n",
    "                        a.append(0)\n",
    "                        red_chi.append(0)\n",
    "                        y_bin_for_yield_min.append(truncate(y_bin_low))\n",
    "                        y_bin_for_yield_max.append(truncate(y_bin_up))\n",
    "                        pt_y_bin_for_yield_min.append(pt_bin_low)\n",
    "                        pt_y_bin_for_yield_max.append(pt_bin_up)\n",
    "                        true_mc_in_recons.append(mc_counts)\n",
    "                                #a.append(tot_sig_3_point_5_sigma)\n",
    "#c . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(red_chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#systematics\n",
    "a = []\n",
    "pt_y_bin_for_yield_min=[]\n",
    "pt_y_bin_for_yield_max=[]\n",
    "y_bin_for_yield_max=[]\n",
    "y_bin_for_yield_min=[]\n",
    "true_mc_in_recons =[]\n",
    "\n",
    "\n",
    "df = df3\n",
    "mass_range_min = [1.08]\n",
    "fit_limit_low=[0,0.1* (df['mass'].describe()[2]),   0.2* (df['mass'].describe()[2]),\n",
    "               1.23,\n",
    "               df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.1* (df['mass'].describe()[2]),\n",
    "                df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.2* (df['mass'].describe()[2])]\n",
    "\n",
    "\n",
    "for mm in mass_range_min:\n",
    "    for mmm in range(0,1,1):\n",
    "\n",
    "        binning = [100, 130, 160]\n",
    "\n",
    "        y_bin_low=-0.2\n",
    "        y_bin_up =0\n",
    "        for i in range(0,15,1):\n",
    "            tot_sig_3_sigma = 0\n",
    "            tot_bac_3_sigma = 0\n",
    "            tot_sig_3_point_5_sigma = 0\n",
    "            tot_bac_3_point_5_sigma = 0\n",
    "            tot_sig_2_point_5_sigma = 0\n",
    "            tot_bac_2_point_5_sigma = 0\n",
    "            tot_sig_2_sigma = 0\n",
    "\n",
    "            y_bin_low = truncate(y_bin_low+0.2)\n",
    "            y_bin_up = truncate(y_bin_up+0.2)\n",
    "            df_y = df[(df['rapidity']>y_bin_low) & (df['rapidity']<y_bin_up)]\n",
    "            pt_bin_low =-0.2\n",
    "            pt_bin_up =0\n",
    "\n",
    "            for i in range(0,15,1):\n",
    "                pt_bin_low = truncate(pt_bin_low+0.2)\n",
    "                #print(pt_bin_low)\n",
    "                pt_bin_up = truncate(pt_bin_up+0.2)\n",
    "                df_pt = df_y[(df_y['pT']>pt_bin_low) & (df_y['pT']<pt_bin_up)]\n",
    "                mc_counts = df_pt[df_pt['issignal']>0].shape[0]\n",
    "                #print(y_bin_low, y_bin_up, \" pT \", pt_bin_low,pt_bin_up)\n",
    "                for b in binning:\n",
    "                    if df_pt.shape[0]>200:\n",
    "                        data0 = background_selector(df_pt)\n",
    "                        h0 = ROOT.TH1F(\"Background\",\"Background without peak\",b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data0.shape[0]):\n",
    "                            h0.Fill(data0.iloc[i])\n",
    "                        fb = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        #fb =TF1(\"fb\",\"[0]+[1]*x+[2]*x*x+[3]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #fb.SetParameters(0,0,0);\n",
    "                        #fb.SetParameters(0,0,0,0);\n",
    "                        h0.Fit(fb,\"RIEM\");\n",
    "                        par = fb.GetParameters()\n",
    "                        #Step 1\n",
    "                        data = df_pt['mass']\n",
    "\n",
    "                #the minimum x (lower edge of the first bin)=mm        \n",
    "                        h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(df_pt['rapidity'].min(),df_pt['rapidity'].max(),df_pt['pT'].min(),df_pt['pT'].max(), mm, b),b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data.shape[0]):\n",
    "                            h1.Fill(data.iloc[i])\n",
    "                        f1 = TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        #f1=TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x+[4]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #f1.SetParameters(1,par[0], par[1], par[2]);\n",
    "                        #f1.SetParameters(1,par[0], par[1], par[2],par[3]);\n",
    "                        f1 = TF1(\"step1\",\"[0]*exp(-0.5*((x-1.115683)/0.0014)^2) +[1]+[2]*x+[3]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        f1.SetParameters(1,par[0], par[1], par[2]);\n",
    "                        h1.Fit(f1,\"RNI\");\n",
    "                        par1 = f1.GetParameters()\n",
    "\n",
    "\n",
    "                #step 2\n",
    "                        f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x+[6]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #f2.SetParameters(par1[0],0.001,1.115,par1[1], par1[2], par1[3], par1[4]);\n",
    "                        #f2.SetParameters(par1[0],0.001,1.115,par1[1], par1[2], par1[3]);\n",
    "                        f2 = TF1(\"full\",\"[0]*exp(-0.5*((x-[2])/[1])^2) +[3]+[4]*x+[5]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        f2.SetParameters(par1[0],0.001,1.115,par1[1],par1[2], par1[3])\n",
    "\n",
    "\n",
    "                        r= ROOT.TFitResultPtr(h1.Fit(f2,\"MNIR\"))\n",
    "                        par2 = f2.GetParameters()\n",
    "\n",
    "                        #fs = TF1(\"fs\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1])\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        #fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "\n",
    "                        fs.SetParameters(par2[0],par2[1],par2[2]);\n",
    "                        fb.SetParameters(par2[3],par2[4],par2[5], par2[6]);\n",
    "\n",
    "                        h2 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        h3 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "\n",
    "\n",
    "                        bin1 = h1.FindBin(fit_limit_low[mmm]+mm);\n",
    "                        bin2 = h1.FindBin(fit_limit_low[mmm+3]);\n",
    "                        for i in range(bin1,bin2):\n",
    "                            f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                            t_value = h1.GetBinContent(i)\n",
    "                            h2.SetBinContent(i,f_value)\n",
    "                            if (h1.GetBinError(i) > 0):\n",
    "                                h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "                        h2.Sumw2()\n",
    "\n",
    "                    #To integrate area under the signal plus background curve we take 3 sigma and integrate\n",
    "                        binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "                        tot = f2.Integral(par2[2] - (TMath.Abs(3*par2[1])),par2[2] + (TMath.Abs(3*par2[1])))/binwidth;\n",
    "                        sigma_integral = f2.IntegralError(par2[2] - (TMath.Abs(3*par2[1])),par2[2] + (TMath.Abs(3*par2[1])));\n",
    "                    #To find the signal, we integrate just the gaussian peak with 3 sigma \n",
    "                        #params.integral = fit->GetParameter(0) * sqrt(2*3.1415) * fit->GetParameter(2) / h->GetBinWidth(1);\n",
    "                        #signal_under_peak = par2[1] * np.sqrt(2*3.1415) *3 *par2[2]/ binwidth\n",
    "                        signal_under_peak = fs.Integral(par2[2] - (TMath.Abs(3*par2[1])),par2[2] + (TMath.Abs(3*par2[1])))/binwidth\n",
    "                        if signal_under_peak<0:\n",
    "                            signal_under_peak = 0\n",
    "                            print('Negative signal')                \n",
    "                        sigma_signal_under_peak = fs.IntegralError(par2[2] - (TMath.Abs(3*par2[1])),par2[2] + (TMath.Abs(3*par2[1])));\n",
    "                        man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "                        if sigma_signal_under_peak!=0:\n",
    "                            print(\"Integral errors \",sigma_signal_under_peak)\n",
    "\n",
    "                        tot_sig_3_sigma= tot_sig_3_sigma+signal_under_peak\n",
    "                    #Background\n",
    "                        backgnd_under_peak = (fb.Integral(par2[2] - (TMath.Abs(3*par2[1])),par2[2] + (TMath.Abs(3*par2[1])))/binwidth)\n",
    "                        if backgnd_under_peak<0:\n",
    "                            print('Negative background')\n",
    "                        sigma_backgnd_under_peak = fb.IntegralError(par2[2] - (TMath.Abs(3*par2[1])),par2[2] + (TMath.Abs(3*par2[1])));\n",
    "                        tot_bac_3_sigma = tot_bac_3_sigma+backgnd_under_peak\n",
    "                    #Significance = signal/(signal+background)^0.5\n",
    "                        Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "\n",
    "                        #3.5 sigma\n",
    "                        signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        tot_sig_3_point_5_sigma = tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma\n",
    "                        tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "                        sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "                        man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "                        signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "                        tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "                        sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "                        man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "                        signal_under_peak_2_sigma = (fs.Integral(par2[2] - (TMath.Abs(2*par2[1])),par2[2] + (TMath.Abs(2*par2[1])))/binwidth);\n",
    "\n",
    "                        draw_hist(h1, f2, fs, fb, h3)\n",
    "\n",
    "\n",
    "            #a.append(tot_sig_2_point_5_sigma)\n",
    "                        a.append(signal_under_peak_2_sigma)\n",
    "                        a.append(signal_under_peak_2_point_5_sigma)\n",
    "                        a.append(signal_under_peak)\n",
    "                        a.append(signal_under_peak_3_point_5_sigma)\n",
    "                        y_bin_for_yield_min.append(truncate(y_bin_low))\n",
    "                        y_bin_for_yield_max.append(truncate(y_bin_up))\n",
    "                        pt_y_bin_for_yield_min.append(pt_bin_low)\n",
    "                        pt_y_bin_for_yield_max.append(pt_bin_up)\n",
    "                        true_mc_in_recons.append(mc_counts)\n",
    "                    else:\n",
    "                        a.append(0)\n",
    "                        a.append(0)\n",
    "                        a.append(0)\n",
    "                        a.append(0)\n",
    "                        y_bin_for_yield_min.append(truncate(y_bin_low))\n",
    "                        y_bin_for_yield_max.append(truncate(y_bin_up))\n",
    "                        pt_y_bin_for_yield_min.append(pt_bin_low)\n",
    "                        pt_y_bin_for_yield_max.append(pt_bin_up)\n",
    "                        true_mc_in_recons.append(mc_counts)\n",
    "            #a.append(tot_sig_3_point_5_sigma)\n",
    "#c . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "file =uproot.open(\"lambda_qa_dcm.root\")\n",
    "array1 = file[\"SimParticles_McLambda/SimParticles_rapidity_SimParticles_pT_McLambda\"].to_numpy()\n",
    "#for i in range(0,14,1):\n",
    "array1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "file =uproot.open(\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/urqmd/c3.root\")\n",
    "array1 = file[\"SimParticles_McLambda/SimParticles_rapidity_SimParticles_pT_McLambda\"].to_numpy()\n",
    "#for i in range(0,14,1):\n",
    "len(array1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "500/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 15*15\n",
    "pt_y_yields = pd.DataFrame(data=np.arange(0,size,1),columns = ['numbering'])\n",
    "pt_y_yields['rapidity_min_MC'] = np.zeros(size)\n",
    "pt_y_yields['pT_min_MC'] = np.zeros(size)\n",
    "\n",
    "pt_y_yields['ratio_recons_sim']=np.zeros(size)\n",
    "pt_y_yields['ratio_recons_mc']=np.zeros(size)\n",
    "pt_y_yields['pT_min'] = np.zeros(size)\n",
    "pt_y_yields ['pt_y_yields_MC']=np.zeros(size)\n",
    "pt_y_yields['pt_y_yields_recons']=a\n",
    "pt_y_yields['true_mc_in_recons'] = true_mc_in_recons\n",
    "#pt_y_yields['total_mc_in_recons'] = dcm_clean_mc\n",
    "\n",
    "for i in range(0,15):\n",
    "    for j in range(0,15):\n",
    "        pt_y_yields['rapidity_min_MC'].iloc[i+j*15]=0+j*0.2\n",
    "    \n",
    "\n",
    "for i in range(0,15):    \n",
    "    pt_y_yields['pT_min_MC'].iloc[i]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+1*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+2*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+3*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+4*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+5*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+6*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+7*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+8*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+9*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+10*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+11*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+12*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+13*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+14*15]=i/5\n",
    "    \n",
    "\n",
    "\n",
    "for i in range(0,15,1):\n",
    "    pt_y_yields ['pt_y_yields_MC'].iloc[i]=array1[0][0][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+1*15]=array1[0][1][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+2*15]=array1[0][2][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+3*15]=array1[0][3][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+4*15]=array1[0][4][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+5*15]=array1[0][5][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+6*15]=array1[0][6][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+7*15]=array1[0][7][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+8*15]=array1[0][8][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+9*15]=array1[0][9][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+10*15]=array1[0][10][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+11*15]=array1[0][11][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+12*15]=array1[0][12][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+13*15]=array1[0][13][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+14*15]=array1[0][14][i]\n",
    "\n",
    "for i in range(0,15*15,1):\n",
    "    pt_y_yields['ratio_recons_mc'].iloc[i]=a[i]/pt_y_yields['true_mc_in_recons'].iloc[i]\n",
    "    pt_y_yields['ratio_recons_sim'].iloc[i]=a[i]/pt_y_yields['pt_y_yields_MC'].iloc[i]\n",
    "    pt_y_yields['pT_min'].iloc[i] = pt_y_bin_for_yield_min[i]\n",
    "    #print(\"%.2f\"%pt_y_yields['rapidity_min_MC'].iloc[i],\"       \",pt_y_yields['pT_min_MC'].iloc[i],\"    \", pt_y_yields['ratio'].iloc[i] )\n",
    "#plt.plot(pt_y_yields['numbering'], pt_y_yields['ratio_recons_sim'], label='Reconstructed/Sim')\n",
    "plt.plot(pt_y_yields['numbering'], pt_y_yields['ratio_recons_mc'], label='Rencostructed/MC')\n",
    "plt.legend()\n",
    "plt.ylim([0.9,1.02])\n",
    "plt.savefig(\"hists\")\n",
    "#pt_y_yields[(pt_y_yields['rapidity_min_MC']>1) & (pt_y_yields['rapidity_min_MC']<1.4) &(pt_y_yields['pT_min_MC']<1)&(pt_y_yields['pT_min_MC']>0)]\n",
    "pt_y_yields[(pt_y_yields['numbering']>70) & (pt_y_yields['numbering']<90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h4 = ROOT.TH2F(\"reduced chi2\", \"reduced chi2\", 15,0,3,15,0,3);\n",
    "#h8 = ROOT.TH2F(\"total mc in reconstructed\", \"total mc in reconstructed\", 15,0,3,15,0,3);\n",
    "\n",
    "\n",
    "h4.SetStats(0)\n",
    "\n",
    "\n",
    "c = ROOT . TCanvas (\" canvas \",\"\", 950,800)\n",
    "c.Draw()\n",
    "bin1 = h4.FindBin(0);\n",
    "bin2 = h4.FindBin(3);\n",
    "for i in range(1,225):\n",
    "    #recons.SetBinContent( (pt_y_yields1['rapidity_min'].iloc[i]), (pt_y_yields1['pT_min'].iloc[i]) ,pt_y_yields1['pt_y_yields'].iloc[i])\n",
    "    y= (pt_y_yields['rapidity_min_MC'].iloc[i])\n",
    "    pT=(pt_y_yields['pT_min_MC'].iloc[i])\n",
    "    y_bin = int((y+0.1)/0.2 + 1);\n",
    "    pT_bin = int((pT+0.1)/0.2 + 1);\n",
    "    h4.SetBinContent(y_bin, pT_bin, red_chi[i]);\n",
    "\n",
    "    #h8.SetBinContent(y_bin, pT_bin, pt_y_yields['total_mc_in_recons'].iloc[i]);\n",
    "\n",
    "c.SetGrid()\n",
    "#h4.Draw('colz')\n",
    "\n",
    "#h5.Draw('colz')\n",
    "#hist_2d.Draw('colz')\n",
    "#ratio_recons_to_recons_mc=h4.Divide(h8)\n",
    "\n",
    "#h6.Draw('colz')\n",
    "\n",
    "h4.Draw('colz')\n",
    "latex1 = ROOT . TLatex ()\n",
    "latex1 . SetNDC ()\n",
    "latex1 . SetTextSize (0.035)\n",
    "latex1 . DrawLatex (0.12 ,0.84, \"CBM performance\")\n",
    "latex1 . DrawLatex (0.12 ,0.76, \"DCM-QGSM-SMM, Au+Au @ 12#it{A} GeV/#it{c}\")\n",
    "latex1 . DrawLatex (0.12 ,0.66, \"Sum of reduced #chi^{2} = %.1f\"%sum(red_chi))\n",
    "latex1.Draw()\n",
    "\n",
    "\n",
    "\n",
    "c.SetRightMargin(0.13);\n",
    "c. Update()\n",
    "c . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "ROOT.gInterpreter.Declare('''\n",
    "TH2F* Divide2DHisto(const TH2F* h1, const TH2F* h2, const TString& name) {\n",
    "\n",
    "  if(h1->GetNbinsX() != h2->GetNbinsX() || h1->GetNbinsY() != h2->GetNbinsY()) {\n",
    "    throw std::runtime_error(\"Histograms should have the same number of bins!\");\n",
    "  }\n",
    "\n",
    "  TH2F* res = dynamic_cast<TH2F*>(h1->Clone(name));\n",
    "  res->Divide(h2);\n",
    "\n",
    "  for(int i = 1; i <= h1->GetNbinsX(); ++i){\n",
    "    for(int j = 1; j <= h1->GetNbinsY(); ++j) {\n",
    "      const auto a = h1->GetBinContent(i, j);\n",
    "      const auto b = h2->GetBinContent(i, j);\n",
    "      const auto da = h1->GetBinError(i, j);\n",
    "      const auto db = h2->GetBinError(i, j);\n",
    "      if(a == 0 || b == 0) {\n",
    "        continue;\n",
    "      }\n",
    "      double error = res->GetBinContent(i, j) * sqrt(da * da / a / a + db * db / b / b);\n",
    "      res->SetBinError(i, j, error);\n",
    "    }\n",
    "  }\n",
    "  return res;\n",
    "}\n",
    "''')\n",
    "\n",
    "ROOT.gInterpreter.Declare('''\n",
    "void PlotHistos(TH1* mc, TH1* reco){\n",
    "  auto c = new TCanvas(reco->GetName(), \"corrected spectra\", 800, 800);\n",
    "  gStyle->SetErrorX(0);\n",
    "  c->SetRightMargin(0.1);\n",
    "  c->SetBottomMargin(0.14);\n",
    "  c->SetTopMargin(1.);\n",
    "  c->SetLeftMargin(.18);\n",
    "  c->Draw();\n",
    "\n",
    "  reco->SetMarkerStyle(21);\n",
    "  reco->SetMarkerColor(kRed);\n",
    "  reco->SetLineColor(kRed);\n",
    "  reco->SetMarkerSize(2);\n",
    "  reco->SetStats(0);\n",
    "  reco->SetTitleSize(0.06);\n",
    "  reco->GetXaxis()->SetRangeUser(0.2, 3);\n",
    "  reco->GetXaxis()->SetTitleOffset(0.9);\n",
    "  reco->GetXaxis()->SetLabelSize(0.05);\n",
    "  reco->GetYaxis()->SetTitleOffset(0.7);\n",
    "  reco->GetYaxis()->SetLabelSize(0.05);\n",
    "  reco->GetYaxis()->SetTitleSize(0.06);\n",
    "  reco->GetXaxis()->SetTitleSize(0.06);\n",
    "//reco->GetYaxis()->SetRangeUser(0, 3000);\n",
    "\n",
    "  \n",
    "  mc->SetMarkerStyle(22);\n",
    "  mc->SetMarkerColor(kBlue);\n",
    "  mc->SetLineColor(kBlue);\n",
    "  mc->SetMarkerSize(2);\n",
    "  mc->SetStats(0);\n",
    "  mc->SetTitleSize(0.06);\n",
    "  mc->GetXaxis()->SetRangeUser(0.2, 3);\n",
    "  mc->GetXaxis()->SetTitleOffset(0.9);\n",
    "  mc->GetXaxis()->SetLabelSize(0.05);\n",
    "  mc->GetYaxis()->SetTitleOffset(0.7);\n",
    "  mc->GetYaxis()->SetLabelSize(0.05);\n",
    "  mc->GetYaxis()->SetTitleSize(0.06);\n",
    "  mc->GetXaxis()->SetTitleSize(0.06);\n",
    "//  mc->GetYaxis()->SetRangeUser(0, 3000);\n",
    "  reco->Draw(\"pe1\");\n",
    "  mc->Draw(\"pe1,same\");\n",
    "  \n",
    "  auto legend = new TLegend(0.9,0.3,0.65,0.2);\n",
    "  legend->AddEntry(mc,\"Simulated\",\"ep\");\n",
    "  legend->AddEntry(reco,\"Efficiency corrected reconstructed\",\"ep\");\n",
    "  legend -> SetLineWidth (0);\n",
    "  legend->Draw();\n",
    "  \n",
    "  auto latex = new TLatex ();\n",
    "  latex->SetNDC ();\n",
    "  latex->SetTextSize (0.039);\n",
    "  latex->DrawLatex (0.12 ,0.24, \"CBM performance\");\n",
    "  latex->DrawLatex (0.12 ,0.16, \"URQMD, Au+Au @ 12#it{A} GeV/#it{c} \" );\n",
    "\n",
    "  latex->Draw();\n",
    "}\n",
    "''')\n",
    "\n",
    "ROOT.gInterpreter.Declare('''\n",
    "void plot_spectra() {\n",
    "\n",
    "  auto file_dcm = TFile::Open(\"new_dcm_100_efficiency_pt_y_yield_bdt_cut_0.9.root\");\n",
    "  auto file_urqmd = TFile::Open(\"new_urqmd_efficiency_pt_y_yield_bdt_cut_0.9.root\");\n",
    "\n",
    "  auto rec_urqmd = file_urqmd->Get<TH2F>(\"recons_urqmd\");\n",
    "  auto sim_urqmd = file_urqmd->Get<TH2F>(\"Mc_urqmd\");\n",
    "  auto rec_dcm = file_dcm->Get<TH2F>(\"recons\");\n",
    "  auto sim_dcm = file_dcm->Get<TH2F>(\"Mc\");\n",
    "\n",
    "  auto eff_urqm = Divide2DHisto(rec_urqmd, sim_urqmd, \"urqmd_eff\");\n",
    "  auto eff_dcm = Divide2DHisto(rec_dcm, sim_dcm, \"dcm_eff\");\n",
    "\n",
    "  auto corr_urqmd = Divide2DHisto(rec_urqmd, eff_dcm, \"corr_urqmd\");\n",
    "  \n",
    "  int bin1 = 6;\n",
    "  int bin2 = 6;\n",
    "  auto corr_urqmd_y = corr_urqmd->ProjectionX(\"corr_urqmd_y\", bin1,bin2);\n",
    "  auto mc_urqmd_y = sim_urqmd->ProjectionX(\"mc_urqmd_y\", bin1,bin2);\n",
    "  \n",
    "  int bin3 = 7;\n",
    "  int bin4 = 7;\n",
    "  auto corr_urqmd_pT = corr_urqmd->ProjectionY(\"corr_urqmd_pT\", bin3,bin4);\n",
    "  auto mc_urqmd_pT = sim_urqmd->ProjectionY(\"mc_urqmd_pT\", bin3,bin4);\n",
    "  \n",
    "  \n",
    "  corr_urqmd_y->SetTitle(Form(\"p_{T} = [%0.1f,%0.1f]\",corr_urqmd->GetYaxis()->GetBinLowEdge(bin1), corr_urqmd->GetYaxis()->GetBinUpEdge(bin2)));\n",
    "  corr_urqmd_y->GetXaxis()->SetTitle(\"#it{y}_{Lab}\");\n",
    "  corr_urqmd_y->GetYaxis()->SetTitle(\"Yield\");\n",
    "  mc_urqmd_y->SetTitle(\"X Projection of Corrected URQMD and MC URQMD\");\n",
    "  mc_urqmd_y->GetXaxis()->SetTitle(\"#it{y}_{Lab}\");\n",
    "  mc_urqmd_y->GetYaxis()->SetTitle(\"Yield\");\n",
    "  \n",
    "  corr_urqmd_pT->SetTitle(Form(\"#it{y}_{LAB} =[%0.1f,%0.1f]\",corr_urqmd->GetYaxis()->GetBinLowEdge(bin3), corr_urqmd->GetYaxis()->GetBinUpEdge(bin4)));\n",
    "  corr_urqmd_pT->GetXaxis()->SetTitle(\"p_{T} (GeV/#it{c})\");\n",
    "  corr_urqmd_pT->GetYaxis()->SetTitle(\"Yield\");\n",
    "  mc_urqmd_pT->SetTitle(\"Y Projection of Corrected URQMD and MC URQMD\");\n",
    "  mc_urqmd_pT->GetXaxis()->SetTitle(\"(GeV/#it{c})\");\n",
    "  mc_urqmd_pT->GetYaxis()->SetTitle(\"Yield\");\n",
    "\n",
    "  \n",
    "  PlotHistos(mc_urqmd_pT, corr_urqmd_pT);\n",
    "  PlotHistos( mc_urqmd_y, corr_urqmd_y);\n",
    "  \n",
    "}\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "ROOT.plot_spectra();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "ROOT.gInterpreter.Declare('''\n",
    "TH2F* Divide2DHisto(const TH2F* h1, const TH2F* h2, const TString& name) {\n",
    "\n",
    "  if(h1->GetNbinsX() != h2->GetNbinsX() || h1->GetNbinsY() != h2->GetNbinsY()) {\n",
    "    throw std::runtime_error(\"Histograms should have the same number of bins!\");\n",
    "  }\n",
    "\n",
    "  TH2F* res = dynamic_cast<TH2F*>(h1->Clone(name));\n",
    "  res->Divide(h2);\n",
    "\n",
    "  for(int i = 1; i <= h1->GetNbinsX(); ++i){\n",
    "    for(int j = 1; j <= h1->GetNbinsY(); ++j) {\n",
    "      const auto a = h1->GetBinContent(i, j);\n",
    "      const auto b = h2->GetBinContent(i, j);\n",
    "      const auto da = h1->GetBinError(i, j);\n",
    "      const auto db = h2->GetBinError(i, j);\n",
    "      if(a == 0 || b == 0) {\n",
    "        continue;\n",
    "      }\n",
    "      double error = res->GetBinContent(i, j) * sqrt(da * da / a / a + db * db / b / b);\n",
    "      res->SetBinError(i, j, error);\n",
    "    }\n",
    "  }\n",
    "  return res;\n",
    "}\n",
    "''')\n",
    "\n",
    "ROOT.gInterpreter.Declare('''\n",
    "void PlotHistos(TH1* mc, TH1* reco){\n",
    "\n",
    "  reco->SetMarkerStyle(21);\n",
    "  reco->SetMarkerColor(kRed);\n",
    "  reco->SetLineColor(kRed);\n",
    "  reco->SetMarkerSize(2);\n",
    "  reco->SetStats(0);\n",
    "  reco->SetTitleSize(0.06);\n",
    "  reco->GetXaxis()->SetRangeUser(0.2, 3);\n",
    "  reco->GetXaxis()->SetTitleOffset(0.9);\n",
    "  reco->GetXaxis()->SetLabelSize(0.05);\n",
    "  reco->GetYaxis()->SetTitleOffset(0.7);\n",
    "  reco->GetYaxis()->SetLabelSize(0.05);\n",
    "  reco->GetYaxis()->SetTitleSize(0.06);\n",
    "  reco->GetXaxis()->SetTitleSize(0.06);\n",
    "//reco->GetYaxis()->SetRangeUser(0, 3000);\n",
    "  reco->Draw(\"pe1\");\n",
    "  \n",
    "  mc->SetMarkerStyle(22);\n",
    "  mc->SetMarkerColor(kBlue);\n",
    "  mc->SetLineColor(kBlue);\n",
    "  mc->SetMarkerSize(2);\n",
    "  mc->SetStats(0);\n",
    "  mc->SetTitleSize(0.06);\n",
    "  mc->GetXaxis()->SetRangeUser(0.2, 3);\n",
    "  mc->GetXaxis()->SetTitleOffset(0.9);\n",
    "  mc->GetXaxis()->SetLabelSize(0.05);\n",
    "  mc->GetYaxis()->SetTitleOffset(0.7);\n",
    "  mc->GetYaxis()->SetLabelSize(0.05);\n",
    "  mc->GetYaxis()->SetTitleSize(0.06);\n",
    "  mc->GetXaxis()->SetTitleSize(0.06);\n",
    "//  mc->GetYaxis()->SetRangeUser(0, 3000);\n",
    "  mc->Draw(\"pe1,same\");\n",
    "  \n",
    "  auto legend = new TLegend(0.9,0.3,0.65,0.2);\n",
    "  legend->AddEntry(mc,\"Simulated\",\"ep\");\n",
    "  legend->AddEntry(reco,\"Efficiency corrected reconstructed\",\"ep\");\n",
    "  legend -> SetLineWidth (0);\n",
    "  legend->SetTextSize(0.39);\n",
    "  legend->Draw();\n",
    "  \n",
    "  \n",
    "  \n",
    "  auto latex = new TLatex ();\n",
    "  latex->SetNDC ();\n",
    "  latex->SetTextSize (0.039);\n",
    "  latex->DrawLatex (0.12 ,0.24, \"scale[1.5]{CBM performance}\");\n",
    "  latex->DrawLatex (0.12 ,0.16, \"scale[1.5]{URQMD, Au+Au @ 12#it{A} GeV/#it{c}}\" );\n",
    "\n",
    "  latex->Draw();\n",
    "}\n",
    "''')\n",
    "\n",
    "ROOT.gInterpreter.Declare('''\n",
    "void plot_spectra() {\n",
    "\n",
    "  auto file_dcm = TFile::Open(\"new_dcm_100_efficiency_pt_y_yield_bdt_cut_0.9.root\");\n",
    "  auto file_urqmd = TFile::Open(\"new_urqmd_efficiency_pt_y_yield_bdt_cut_0.9.root\");\n",
    "\n",
    "  auto rec_urqmd = file_urqmd->Get<TH2F>(\"recons_urqmd\");\n",
    "  auto sim_urqmd = file_urqmd->Get<TH2F>(\"Mc_urqmd\");\n",
    "  auto rec_dcm = file_dcm->Get<TH2F>(\"recons\");\n",
    "  auto sim_dcm = file_dcm->Get<TH2F>(\"Mc\");\n",
    "\n",
    "  auto eff_urqm = Divide2DHisto(rec_urqmd, sim_urqmd, \"urqmd_eff\");\n",
    "  auto eff_dcm = Divide2DHisto(rec_dcm, sim_dcm, \"dcm_eff\");\n",
    "\n",
    "  auto corr_urqmd = Divide2DHisto(rec_urqmd, eff_dcm, \"corr_urqmd\");\n",
    "  \n",
    "  int bin1 = 6;\n",
    "  int bin2 = 6;\n",
    "  auto corr_urqmd_y = corr_urqmd->ProjectionX(\"corr_urqmd_y\", bin1,bin2);\n",
    "  auto mc_urqmd_y = sim_urqmd->ProjectionX(\"mc_urqmd_y\", bin1,bin2);\n",
    "  \n",
    "  int bin3 = 7;\n",
    "  int bin4 = 7;\n",
    "  auto corr_urqmd_pT = corr_urqmd->ProjectionY(\"corr_urqmd_pT\", bin3,bin4);\n",
    "  auto mc_urqmd_pT = sim_urqmd->ProjectionY(\"mc_urqmd_pT\", bin3,bin4);\n",
    "  \n",
    "  \n",
    "  corr_urqmd_y->SetTitle(Form(\"p_{T} = [%0.1f,%0.1f]\",corr_urqmd->GetYaxis()->GetBinLowEdge(bin1), corr_urqmd->GetYaxis()->GetBinUpEdge(bin2)));\n",
    "  corr_urqmd_y->GetXaxis()->SetTitle(\"#it{y}_{Lab}\");\n",
    "  corr_urqmd_y->GetYaxis()->SetTitle(\"Yield\");\n",
    "  mc_urqmd_y->SetTitle(\"X Projection of Corrected URQMD and MC URQMD\");\n",
    "  mc_urqmd_y->GetXaxis()->SetTitle(\"#it{y}_{Lab}\");\n",
    "  mc_urqmd_y->GetYaxis()->SetTitle(\"Yield\");\n",
    "  \n",
    "  corr_urqmd_pT->SetTitle(Form(\"#it{y}_{LAB} =[%0.1f,%0.1f]\",corr_urqmd->GetYaxis()->GetBinLowEdge(bin3), corr_urqmd->GetYaxis()->GetBinUpEdge(bin4)));\n",
    "  corr_urqmd_pT->GetXaxis()->SetTitle(\"p_{T} (GeV/#it{c})\");\n",
    "  corr_urqmd_pT->GetYaxis()->SetTitle(\"Yield\");\n",
    "  mc_urqmd_pT->SetTitle(\"Y Projection of Corrected URQMD and MC URQMD\");\n",
    "  mc_urqmd_pT->GetXaxis()->SetTitle(\"(GeV/#it{c})\");\n",
    "  mc_urqmd_pT->GetYaxis()->SetTitle(\"Yield\");\n",
    "\n",
    "  auto c = new TCanvas (\" canvas \",\"\", 800,800);\n",
    "  c->Draw();\n",
    "  gStyle->SetErrorX(0);\n",
    "  c->Divide(1,2);\n",
    "  TPad *pad1 = (TPad*)c->cd(1);\n",
    "  pad1->SetBottomMargin (0);\n",
    "  pad1->Draw ();\n",
    "  pad1->cd();\n",
    "  PlotHistos(mc_urqmd_pT, corr_urqmd_pT);\n",
    "  \n",
    "  \n",
    "  TPad *pad2 = (TPad*)c->cd(2);\n",
    "  pad2->SetTopMargin (0);\n",
    "  pad2->SetBottomMargin (0.05);\n",
    "  pad2->Draw ();\n",
    "  pad2->cd ();\n",
    "  PlotHistos( mc_urqmd_y, corr_urqmd_y);\n",
    "  //c1->SaveAs(\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf\")\n",
    "  \n",
    "}\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "ROOT.plot_spectra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
